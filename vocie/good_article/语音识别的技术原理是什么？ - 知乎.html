<!doctype html>
<html lang="zh" data-reactroot="" data-reactid="1" data-react-checksum="-1969955077"><head data-reactid="2"><meta charset="utf-8" data-reactid="3"/><title data-react-helmet="true" data-reactid="4">语音识别的技术原理是什么？ - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1" data-reactid="5"/><meta name="renderer" content="webkit" data-reactid="6"/><meta name="force-rendering" content="webkit" data-reactid="7"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" data-reactid="8"/><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg" data-reactid="9"/><meta data-react-helmet="true" name="apple-itunes-app" content="app-id=432274380, app-argument=zhihu://questions/20398418" data-reactid="10"/><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico" data-reactid="11"/><link rel="dns-prefetch" href="//static.zhimg.com" data-reactid="12"/><link rel="dns-prefetch" href="//pic1.zhimg.com" data-reactid="13"/><link rel="dns-prefetch" href="//pic2.zhimg.com" data-reactid="14"/><link rel="dns-prefetch" href="//pic3.zhimg.com" data-reactid="15"/><link rel="dns-prefetch" href="//pic4.zhimg.com" data-reactid="16"/><link href="https://static.zhihu.com/heifetz/main.app.47898a4bd081ca725e50.css" rel="stylesheet" data-reactid="17"/></head><body class="Entry-body" data-reactid="18"><div id="root" data-reactid="19"><div data-zop-userToken="{}"><div class="LoadingBar"></div><div><header role="banner" class="Sticky AppHeader" data-za-module="TopNavBar"><div class="AppHeader-inner"><a href="/" aria-label="知乎"><svg viewBox="0 0 200 91" class="Icon Icon--logo" style="fill:#0f88eb;height:30px;width:64px;" width="64" height="30" aria-hidden="true"><title></title><g><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"/></g></svg></a><nav role="navigation" class="AppHeader-nav"><a class="AppHeader-navItem" href="/">首页</a><a class="AppHeader-navItem" href="/explore">发现</a><a class="AppHeader-navItem" href="/topic">话题</a></nav><div class="SearchBar" role="search"><div class="SearchBar-toolWrapper"><form class="SearchBar-tool"><div><div class="Popover"><div class="SearchBar-input Input-wrapper Input-wrapper--grey"><input type="text" maxlength="100" value="" autocomplete="off" role="combobox" aria-expanded="false" aria-autocomplete="list" aria-activedescendant="null--1" id="null-toggle" aria-haspopup="true" aria-owns="null-content" class="Input" placeholder="搜索你感兴趣的内容…"/><div class="Input-after"><button class="Button SearchBar-searchIcon Button--primary" aria-label="搜索" type="button"><svg viewBox="0 0 16 16" class="Icon Icon--search" style="height:16px;width:16px;" width="16" height="16" aria-hidden="true"><title></title><g><path d="M12.054 10.864c.887-1.14 1.42-2.57 1.42-4.127C13.474 3.017 10.457 0 6.737 0S0 3.016 0 6.737c0 3.72 3.016 6.737 6.737 6.737 1.556 0 2.985-.533 4.127-1.42l3.103 3.104c.765.46 1.705-.37 1.19-1.19l-3.103-3.104zm-5.317.925c-2.786 0-5.053-2.267-5.053-5.053S3.95 1.684 6.737 1.684 11.79 3.95 11.79 6.737 9.522 11.79 6.736 11.79z"/></g></svg></button></div></div></div></div></form></div></div><div class="AppHeader-userInfo"><div class="AppHeader-profile"><div><button class="Button AppHeader-login Button--blue" type="button">登录</button><button class="Button Button--primary Button--blue" type="button">加入知乎</button></div></div></div></div></header></div><main role="main" class="App-main"><div class="QuestionPage" itemscope="" itemtype="http://schema.org/Question"><meta itemprop="name" content="语音识别的技术原理是什么？"/><meta itemprop="url" content="https://www.zhihu.com/question/20398418"/><meta itemprop="keywords" content="人工智能,科普,语音识别,X 的原理,X 的工作原理"/><meta itemprop="answerCount" content="23"/><meta itemprop="commentCount" content="3"/><meta itemprop="dateCreated" content="2012-08-03T15:01:08.000Z"/><meta itemprop="dateModified" content="2017-05-07T15:17:32.000Z"/><meta itemprop="zhihu:visitsCount"/><meta itemprop="zhihu:followerCount" content="4567"/><div data-zop-question="{&quot;title&quot;:&quot;语音识别的技术原理是什么？&quot;,&quot;topics&quot;:[{&quot;name&quot;:&quot;人工智能&quot;,&quot;id&quot;:&quot;19551275&quot;},{&quot;name&quot;:&quot;科普&quot;,&quot;id&quot;:&quot;19551585&quot;},{&quot;name&quot;:&quot;语音识别&quot;,&quot;id&quot;:&quot;19560846&quot;},{&quot;name&quot;:&quot;X 的原理&quot;,&quot;id&quot;:&quot;19561178&quot;},{&quot;name&quot;:&quot;X 的工作原理&quot;,&quot;id&quot;:&quot;19566024&quot;}],&quot;id&quot;:20398418,&quot;isEditable&quot;:false}"><div class="QuestionHeader"><div class="QuestionHeader-content"><div class="QuestionHeader-main"><div class="QuestionHeader-tags"><div class="QuestionHeader-topics"><div class="Tag QuestionTopic"><span class="Tag-content"><a class="TopicLink" href="/topic/19551275"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">人工智能</div></div></a></span></div><div class="Tag QuestionTopic"><span class="Tag-content"><a class="TopicLink" href="/topic/19551585"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">科普</div></div></a></span></div><div class="Tag QuestionTopic"><span class="Tag-content"><a class="TopicLink" href="/topic/19560846"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">语音识别</div></div></a></span></div><div class="Tag QuestionTopic"><span class="Tag-content"><a class="TopicLink" href="/topic/19561178"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">X 的原理</div></div></a></span></div><div class="Tag QuestionTopic"><span class="Tag-content"><a class="TopicLink" href="/topic/19566024"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content">X 的工作原理</div></div></a></span></div></div></div><h1 class="QuestionHeader-title">语音识别的技术原理是什么？</h1><div class="QuestionHeader-detail"><div class="QuestionRichText QuestionRichText--expandable QuestionRichText--collapsed"><div><span class="RichText" itemprop="text">本题已收录至知乎圆桌：<a href="https://www.zhihu.com/roundtable/ziranyuyan" class="internal">人工智能 · 语言智能</a>，更多「人工智能」相关话题欢迎关注讨论</span><button class="Button QuestionRichText-more Button--plain" type="button">显示全部<svg viewBox="0 0 10 6" class="Icon QuestionRichText-more-icon Icon--arrow" style="height:16px;width:10px;" width="10" height="16" aria-hidden="true"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"/></g></svg></button></div></div></div></div><div class="QuestionHeader-side"><div class="QuestionHeader-follow-status"><div class="QuestionFollowStatus"><div class="NumberBoard QuestionFollowStatus-counts"><div class="NumberBoard-item"><div class="NumberBoard-name">关注者</div><div class="NumberBoard-value">4567</div></div><div class="NumberBoard-divider"></div><div class="NumberBoard-item"><div class="NumberBoard-name">被浏览</div><div class="NumberBoard-value">317537</div></div></div></div></div></div></div><div class="QuestionHeader-footer"><div class="QuestionHeader-footer-inner"><div class="QuestionHeader-main QuestionHeader-footer-main"><div class="QuestionHeaderActions"><div class="QuestionHeader-Comment"><button class="Button Button--plain" type="button"><svg viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--comment Icon--left" style="height:15px;width:20px;" width="20" height="15" aria-hidden="true"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"/></g></svg>3 条评论</button></div><div class="Popover ShareMenu"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--share Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"/></g></svg>分享</button></div></div><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"/></g></svg>邀请回答</button><div class="Popover"><button class="Button Button--plain" type="button" id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><svg viewBox="0 0 18 4" class="Icon Icon--dots" style="height:16px;width:14px;" width="14" height="16" aria-hidden="true"><title></title><g><g><circle cx="2" cy="2" r="2"/><circle cx="9" cy="2" r="2"/><circle cx="16" cy="2" r="2"/></g></g></svg></button></div></div><div class="QuestionHeader-actions"></div></div><div class="QuestionHeader-side"><div class="QuestionButtonGroup"><button class="Button Button--primary Button--blue" type="button">关注问题</button><button class="Button Button--blue" type="button"><svg viewBox="0 0 12 12" class="Icon Button-icon Icon--modify" style="height:16px;width:14px;" width="14" height="16" aria-hidden="true"><title></title><g><path d="M.423 10.32L0 12l1.667-.474 1.55-.44-2.4-2.33-.394 1.564zM10.153.233c-.327-.318-.85-.31-1.17.018l-.793.817 2.49 2.414.792-.814c.318-.328.312-.852-.017-1.17l-1.3-1.263zM3.84 10.536L1.35 8.122l6.265-6.46 2.49 2.414-6.265 6.46z" fill-rule="evenodd"/></g></svg>写回答</button></div></div></div></div></div><div><div><div class="Sticky"></div></div></div></div><div class="Question-main"><div class="Question-mainColumn"><div><div id="QuestionAnswers-answers" class="QuestionAnswers-answers"><div class="Card"><div class="List"><div class="List-header"><h4 class="List-headerText"><span>23 个回答</span></h4><div class="List-headerOptions"><div class="Popover"><button class="Button Select-button Select-plainButton Button--plain" role="combobox" aria-expanded="false" type="button" id="null-toggle" aria-haspopup="true" aria-owns="null-content">默认排序<svg viewBox="0 0 8 13" class="Icon Select-arrow Icon--select" style="height:16px;width:8px;" width="8" height="16" aria-hidden="true"><title></title><g><path d="M4 11.183L1.284 8.218c-.293-.29-.77-.29-1.064 0-.293.29-.293.76 0 1.052l3.25 3.512c.292.29.768.29 1.062 0L7.78 9.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.064 0L4 11.182zM4 1.818L1.284 4.782c-.293.29-.77.29-1.064 0-.293-.29-.293-.76 0-1.052L3.47.218c.292-.29.768-.29 1.062 0L7.78 3.73c.293.29.293.76 0 1.052-.295.29-.77.29-1.064 0L4 1.82z"/></g></svg></button></div></div></div><div data-zop-feedlist="true"><div class="List-item"><div class="ContentItem AnswerItem" data-za-index="0" data-zop="{&quot;authorName&quot;:&quot;张俊博&quot;,&quot;itemId&quot;:18080841,&quot;title&quot;:&quot;语音识别的技术原理是什么？&quot;,&quot;type&quot;:&quot;answer&quot;}" name="18080841" itemprop="acceptedAnswer" itemtype="http://schema.org/Answer" itemscope=""><div class="ContentItem-meta"><div class="AnswerItem-meta AnswerItem-meta--related"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="张俊博"/><meta itemprop="image" content="https://pic1.zhimg.com/1be9d5c0ccc6b73c724ed50812dc2350_is.jpg"/><meta itemprop="url" content="https://www.zhihu.com/people/jimbozhang"/><meta itemprop="zhihu:followerCount" content="2061"/><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" href="/people/jimbozhang"><img class="Avatar AuthorInfo-avatar" width="38" height="38" src="https://pic1.zhimg.com/1be9d5c0ccc6b73c724ed50812dc2350_xs.jpg" srcset="https://pic1.zhimg.com/1be9d5c0ccc6b73c724ed50812dc2350_l.jpg 2x" alt="张俊博"/></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><a class="UserLink-link" data-za-detail-view-element_name="User" href="/people/jimbozhang">张俊博</a></div></div></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="RichText AuthorInfo-badgeText">小米语音</div></div></div></div></div><div class="AnswerItem-extraInfo"><span>收录于 <span class="AnswerItem-markInfoItem">编辑推荐</span><span class="AnswerItem-markInfoItem">知乎周刊</span></span> · <span class="Voters"><button class="Button Button--plain" type="button">2178 人赞同了该回答</button></span></div></div></div><meta itemprop="image" content="https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_200x112.jpg"/><meta itemprop="upvoteCount" content="2178"/><meta itemprop="url" content="https://www.zhihu.com/question/20398418/answer/18080841"/><meta itemprop="dateCreated" content="2013-07-26T13:36:12.000Z"/><meta itemprop="dateModified" content="2017-01-14T02:53:57.000Z"/><meta itemprop="commentCount" content="111"/><div class="RichContent RichContent--unescapable"><div class="RichContent-inner"><span class="RichText CopyrightRichText-richText" itemprop="text">简要给大家介绍一下语音怎么变文字的吧。<b>需要说明的是，这篇文章为了易读性而牺牲了严谨性，因此文中的很多表述实际上是不准确的。</b>对于有兴趣深入了解的同学，本文的末尾推荐了几份进阶阅读材料。下面我们开始。<br><br>首先，我们知道声音实际上是一种波。常见的mp3等格式都是压缩格式，必须转成非压缩的纯波形文件来处理，比如Windows PCM文件，也就是俗称的wav文件。wav文件里存储的除了一个文件头以外，就是声音波形的一个个点了。下图是一个波形的示例。<br><br><noscript><img src="https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_b.jpg" data-rawheight="119" data-rawwidth="482" class="origin_image zh-lightbox-thumb" width="482" data-original="https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_r.jpg"></noscript><img src="//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg" data-rawheight="119" data-rawwidth="482" class="origin_image zh-lightbox-thumb lazy" width="482" data-original="https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_r.jpg" data-actualsrc="https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_b.jpg"><br>在开始语音识别之前，有时需要把首尾端的静音切除，降低对后续步骤造成的干扰。这个静音切除的操作一般称为VAD，需要用到信号处理的一些技术。<br><br>要对声音进行分析，需要对声音分帧，也就是把声音切开成一小段一小段，每小段称为一帧。分帧操作一般不是简单的切开，而是使用移动窗函数来实现，这里不详述。帧与帧之间一般是有交叠的，就像下图这样：<br><noscript><img src="https://pic3.zhimg.com/554db0c9107727aa1e31a62cca782ada_b.jpg" data-rawheight="175" data-rawwidth="343" class="content_image" width="343">图中，每帧的长度为25毫秒，每两帧之间有25-10=15毫秒的交叠。我们称为以帧长25ms、帧移10ms分帧。</noscript><img src="//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg" data-rawheight="175" data-rawwidth="343" class="content_image lazy" width="343" data-actualsrc="https://pic3.zhimg.com/554db0c9107727aa1e31a62cca782ada_b.jpg">图中，每帧的长度为25毫秒，每两帧之间有25-10=15毫秒的交叠。我们称为以帧长25ms、帧移10ms分帧。<br><br>分帧后，语音就变成了很多小段。但波形在时域上几乎没有描述能力，因此必须将波形作变换。常见的一种变换方法是提取MFCC特征，根据人耳的生理特性，把每一帧波形变成一个多维向量，可以简单地理解为这个向量包含了这帧语音的内容信息。这个过程叫做声学特征提取。实际应用中，这一步有很多细节，声学特征也不止有MFCC这一种，具体这里不讲。<br><br>至此，声音就成了一个12行（假设声学特征是12维）、N列的一个矩阵，称之为观察序列，这里N为总帧数。观察序列如下图所示，图中，每一帧都用一个12维的向量表示，色块的颜色深浅表示向量值的大小。<br><noscript><img src="https://pic4.zhimg.com/c5cc0131dc6d38e871953eea0792f7db_b.jpg" data-rawheight="318" data-rawwidth="301" class="content_image" width="301"></noscript><img src="//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg" data-rawheight="318" data-rawwidth="301" class="content_image lazy" width="301" data-actualsrc="https://pic4.zhimg.com/c5cc0131dc6d38e871953eea0792f7db_b.jpg"><br>接下来就要介绍怎样把这个矩阵变成文本了。首先要介绍两个概念：<br><ol><li>音素：单词的发音由音素构成。对英语，一种常用的音素集是卡内基梅隆大学的一套由39个音素构成的音素集，参见<a href="https://link.zhihu.com/?target=http%3A//www.speech.cs.cmu.edu/cgi-bin/cmudict" class=" wrap external" target="_blank" rel="nofollow noreferrer">The CMU Pronouncing Dictionary<i class="icon-external"></i></a>‎。汉语一般直接用全部声母和韵母作为音素集，另外汉语识别还分有调无调，不详述。<br></li><li>状态：这里理解成比音素更细致的语音单位就行啦。通常把一个音素划分成3个状态。</li></ol><br>语音识别是怎么工作的呢？实际上一点都不神秘，无非是：<br>把帧识别成状态（难点）。<br>把状态组合成音素。<br>把音素组合成单词。<br><br>如下图所示：<br><noscript><img src="https://pic2.zhimg.com/beee2a3ce7b1b56de362c9015e5b8ccd_b.jpg" data-rawheight="257" data-rawwidth="457" class="origin_image zh-lightbox-thumb" width="457" data-original="https://pic2.zhimg.com/beee2a3ce7b1b56de362c9015e5b8ccd_r.jpg">图中，每个小竖条代表一帧，若干帧语音对应一个状态，每三个状态组合成一个音素，若干个音素组合成一个单词。也就是说，只要知道每帧语音对应哪个状态了，语音识别的结果也就出来了。</noscript><img src="//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg" data-rawheight="257" data-rawwidth="457" class="origin_image zh-lightbox-thumb lazy" width="457" data-original="https://pic2.zhimg.com/beee2a3ce7b1b56de362c9015e5b8ccd_r.jpg" data-actualsrc="https://pic2.zhimg.com/beee2a3ce7b1b56de362c9015e5b8ccd_b.jpg">图中，每个小竖条代表一帧，若干帧语音对应一个状态，每三个状态组合成一个音素，若干个音素组合成一个单词。也就是说，只要知道每帧语音对应哪个状态了，语音识别的结果也就出来了。<br><br>那每帧音素对应哪个状态呢？有个容易想到的办法，看某帧对应哪个状态的概率最大，那这帧就属于哪个状态。比如下面的示意图，这帧在状态S3上的条件概率最大，因此就猜这帧属于状态S3。<noscript><img src="https://pic2.zhimg.com/61d5bff9c239e7519e92d98f5bc44689_b.jpg" data-rawheight="211" data-rawwidth="341" class="content_image" width="341"></noscript><img src="//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg" data-rawheight="211" data-rawwidth="341" class="content_image lazy" width="341" data-actualsrc="https://pic2.zhimg.com/61d5bff9c239e7519e92d98f5bc44689_b.jpg"><br><br>那这些用到的概率从哪里读取呢？有个叫“声学模型”的东西，里面存了一大堆参数，通过这些参数，就可以知道帧和状态对应的概率。获取这一大堆参数的方法叫做“训练”，需要使用巨大数量的语音数据，训练的方法比较繁琐，这里不讲。<br><br>但这样做有一个问题：每一帧都会得到一个状态号，最后整个语音就会得到一堆乱七八糟的状态号。假设语音有1000帧，每帧对应1个状态，每3个状态组合成一个音素，那么大概会组合成300个音素，但这段语音其实根本没有这么多音素。如果真这么做，得到的状态号可能根本无法组合成音素。实际上，相邻帧的状态应该大多数都是相同的才合理，因为每帧很短。<br><br>解决这个问题的常用方法就是使用隐马尔可夫模型（Hidden Markov Model，HMM）。这东西听起来好像很高深的样子，实际上用起来很简单：<br>第一步，构建一个状态网络。<br>第二步，从状态网络中寻找与声音最匹配的路径。<br><br>这样就把结果限制在预先设定的网络中，避免了刚才说到的问题，当然也带来一个局限，比如你设定的网络里只包含了“今天晴天”和“今天下雨”两个句子的状态路径，那么不管说些什么，识别出的结果必然是这两个句子中的一句。<br><br>那如果想识别任意文本呢？把这个网络搭得足够大，包含任意文本的路径就可以了。但这个网络越大，想要达到比较好的识别准确率就越难。所以要根据实际任务的需求，合理选择网络大小和结构。<br><br>搭建状态网络，是由单词级网络展开成音素网络，再展开成状态网络。语音识别过程其实就是在状态网络中搜索一条最佳路径，语音对应这条路径的概率最大，这称之为“解码”。路径搜索的算法是一种动态规划剪枝的算法，称之为Viterbi算法，用于寻找全局最优路径。<br><br><noscript><img src="https://pic1.zhimg.com/91e4cb3b716b63d5e18ba710a1a2d770_b.jpg" data-rawheight="329" data-rawwidth="621" class="origin_image zh-lightbox-thumb" width="621" data-original="https://pic1.zhimg.com/91e4cb3b716b63d5e18ba710a1a2d770_r.jpg"></noscript><img src="//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg" data-rawheight="329" data-rawwidth="621" class="origin_image zh-lightbox-thumb lazy" width="621" data-original="https://pic1.zhimg.com/91e4cb3b716b63d5e18ba710a1a2d770_r.jpg" data-actualsrc="https://pic1.zhimg.com/91e4cb3b716b63d5e18ba710a1a2d770_b.jpg"><br>这里所说的累积概率，由三部分构成，分别是：<br><ol><li>观察概率：每帧和每个状态对应的概率</li><li>转移概率：每个状态转移到自身或转移到下个状态的概率</li><li>语言概率：根据语言统计规律得到的概率</li></ol>其中，前两种概率从声学模型中获取，最后一种概率从语言模型中获取。语言模型是使用大量的文本训练出来的，可以利用某门语言本身的统计规律来帮助提升识别正确率。语言模型很重要，如果不使用语言模型，当状态网络较大时，识别出的结果基本是一团乱麻。<br><br><br>这样基本上语音识别过程就完成了。<br><br>以上的文字只是想让大家容易理解，并不追求严谨。事实上，HMM的内涵绝不是上面所说的“无非是个状态网络”，如果希望深入了解，下面给出了几篇阅读材料：<br><br>1. Rabiner L R. <i>A tutorial on hidden Markov models and selected applications in speech recognition</i>. Proceedings of the IEEE, 1989, 77(2): 257-286.<br>入门必读。深入浅出地介绍了基于HMM的语音识别的原理，不注重公式的细节推导而是着重阐述公式背后的物理意义。<br><br>2. Bilmes J A. <i>A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models</i>. International Computer Science Institute, 1998, 4(510): 126.<br>详细介绍了用E-M算法训练HMM参数的推导过程，首先讲E-M的基本原理，然后讲解如何应用到GMM的训练，最后讲解如何应用到HMM的训练。<br><br>3. Young S, Evermann G, Gales M, et al. <i>The HTK book (v3.4)</i>. Cambridge University, 2006.<br>HTK Book，开源工具包HTK的文档。虽然现在HTK已经不是最流行的了，但仍然强烈推荐按照书里的第二章流程做一遍，你可以搭建出一个简单的数字串识别系统。<br><br>4. Graves A. <i>Supervised Sequence Labelling with Recurrent Neural Networks</i>. Springer Berlin Heidelberg, 2012: 15-35.<br>基于神经网络的语音识别的入门必读。从神经网络的基本结构、BP算法等介绍到 LSTM、CTC。<br><br>5. 俞栋, 邓力. <i>解析深度学习——语音识别实践</i>, 电子工业出版社, 2016.<br>高质量的中文资料非常稀有，推荐买一本。最早把深度学习技术应用于语音识别就是这本书的作者。</span></div><div><div class="ContentItem-time"><a target="_blank" href="/question/20398418/answer/18080841"><span data-tooltip="发布于 2013-07-26">编辑于 2017-01-14</span></a></div></div><div class="ContentItem-actions RichContent-actions"><span><button class="Button VoteButton VoteButton--up" aria-label="赞同" type="button"><svg viewBox="0 0 20 18" class="Icon VoteButton-upIcon Icon--triangle" style="height:16px;width:9px;" width="9" height="16" aria-hidden="true"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"/></g></svg>2.2K</button><button class="Button VoteButton VoteButton--down" aria-label="反对" type="button"><svg viewBox="0 0 20 18" class="Icon VoteButton-downIcon Icon--triangle" style="height:16px;width:9px;" width="9" height="16" aria-hidden="true"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"/></g></svg></button></span><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--comment Icon--left" style="height:16px;width:12px;" width="12" height="16" aria-hidden="true"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"/></g></svg>111 条评论</button><div class="Popover ShareMenu ContentItem-action"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--share Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"/></g></svg>分享</button></div></div><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"/></g></svg>收藏</button><button class="Button ContentItem-action Button--plain" type="button"><svg width="14" height="16" viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--thank Icon--left" style="height:16px;width:14px;" aria-hidden="true"><title></title><g><path d="M0 5.437C0 2.505 2.294.094 5.207 0 7.243 0 9.092 1.19 10 3c.823-1.758 2.65-3 4.65-3C17.546 0 20 2.507 20 5.432 20 13.24 11.842 18 10 18 8.158 18 0 13.24 0 5.437z" fill-rule="evenodd"/></g></svg>感谢</button><button class="Button ContentItem-action ContentItem-rightButton Button--plain" data-zop-retract-question="true" type="button"><span class="RichContent-collapsedText">收起</span><svg viewBox="0 0 10 6" class="Icon ContentItem-arrowIcon is-active Icon--arrow" style="height:16px;width:10px;" width="10" height="16" aria-hidden="true"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"/></g></svg></button></div></div></div></div><div class="List-item"><div class="ContentItem AnswerItem" data-za-index="1" data-zop="{&quot;authorName&quot;:&quot;知乎用户&quot;,&quot;itemId&quot;:71349128,&quot;title&quot;:&quot;语音识别的技术原理是什么？&quot;,&quot;type&quot;:&quot;answer&quot;}" name="71349128" itemprop="suggestedAnswer" itemtype="http://schema.org/Answer" itemscope=""><div class="ContentItem-meta"><div class="AnswerItem-meta AnswerItem-meta--related"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="知乎用户"/><meta itemprop="image" content="https://pic1.zhimg.com/da8e974dc_is.jpg"/><meta itemprop="url" content="https://www.zhihu.com/people/"/><meta itemprop="zhihu:followerCount" content="934"/><span class="UserLink AuthorInfo-avatarWrapper"><img class="Avatar AuthorInfo-avatar" width="38" height="38" src="https://pic1.zhimg.com/da8e974dc_xs.jpg" srcset="https://pic1.zhimg.com/da8e974dc_l.jpg 2x" alt="知乎用户"/></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name">知乎用户</span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"></div></div></div></div><div class="AnswerItem-extraInfo"><span>收录于 <span class="AnswerItem-markInfoItem">编辑推荐</span><a class="AnswerItem-markInfoItem" href="https://www.zhihu.com/roundtable/ziranyuyan">知乎圆桌</a></span> · <span class="Voters"><button class="Button Button--plain" type="button">181 人赞同了该回答</button></span></div></div></div><meta itemprop="image" content=""/><meta itemprop="upvoteCount" content="181"/><meta itemprop="url" content="https://www.zhihu.com/question/20398418/answer/71349128"/><meta itemprop="dateCreated" content="2015-11-08T10:31:33.000Z"/><meta itemprop="dateModified" content="2016-07-29T07:23:09.000Z"/><meta itemprop="commentCount" content="15"/><div class="RichContent RichContent--unescapable"><div class="RichContent-inner"><span class="RichText CopyrightRichText-richText" itemprop="text">楼上张俊博的回答比较仔细的讲解了基础的经典语音识别算法。我想对算法背后的含义做一个简单的解释，对涉及到的特征提取（包括分帧）、音素建模、字典、隐式马尔科夫模型等可以参阅楼上的回答。<br><br>语音识别的第一个特点是要识别的语音的内容（比声韵母等）是不定长时序，也就是说，在识别以前你不可能知道当前的 声韵母有多长，这样在构建统计模型输入语音特征的时候无法简单判定到底该输入0.0到0.5秒还是0.2到0.8秒进行识别，同时多数常见的模型都不方便处理维度不确定的输入特征（注意在一次处理的时候，时间长度转化成了当前的特征维度）。一种简单的解决思路是对语音进行分帧，每一帧占有比较短固定的时 长（比如25ms），再假设说这样的一帧既足够长（可以蕴含 足以判断它属于哪个声韵母的信息），又很平稳（方便进行短时傅里叶分析），这样将每一帧转换为一个特征向量，（依次）分别识别它们属于哪个声韵母，就可以 解决问题。识别的结果可以是比如第100到第105帧是声母c，而第106帧到115帧是韵母eng等。 这种思路有点类似微积分 中的『以直代曲』。另外在实际的分帧过程中，还有很多常用技巧，比如相邻两帧之间有所重叠，或引入与临近帧之间的差分作为额外特征，乃至直接堆叠许多语音帧等等，这些都可以让前述的两个假设更可靠。近年来，研究种也出现了一些更新颖的处理方式，比如用.wav文件的采样点取代分帧并处理后的语音帧，但这样的方法在处理速度及性能上 暂时还没有优势。<br><br>当我们有了分帧后的语音特征之后，下一步常用的处理是使用某种分类器将之分类成某种跟语音内容相关的类别，如声韵母，这一步通常称作声学模型建模。对于分类目标的选取，最简单的选择可以是词组，或者是组成词组的汉字所对应的音节。但这样的选择方式通常会对训练模型的语音数据提出过高的要求，带来『数据稀疏』的问题，即数据中 很难包含汉语中的所有词组，同时每个词组也很难具有充足的训练样本以保证统计声学模型的可靠性。由于一个词组通常由多个音素的连续发音 构成，常见的音素都包含在国际音标表中，它们具有恰当的数目（通常几十个），以及清晰的定义（由特定的发声器官运动产生），于是音素成了各种语言中的语音识别中都最为常见的 建模选择（汉语的声韵母也是由一到三个音素构成）， 识别中再结合词组到音素的发音字典使用。使用音素也方便对混合语言（如汉语种夹杂英语词汇）进行识别——当然不同母语的人对相同音素的发音也有区别，这是另外一个话题。另外由于人类发生器官运动的连续性，以及某些语言中特定的拼读习惯（比如英语中定冠词『the』在元音和辅音之前有不同读音），会导致发音，尤其是音素的发音受到前后音素的影响，称为『协同发音』。于是 可以进行所谓『上下文相关』的音素（或者考虑到音素实际的拼读，称为音子）分类。比如wo chi le这个序列，可以写为w o ch i l e，这样是普通的『上下文无关』音子序列，也可以考虑前一个音素对当前音素的影响写成sil-w w-o o-ch ch-i i-l l-e （sil表示语音开始前的静音，A-B表示收到A影响的B）或考虑后一个音素的影响写成w+o o+ch ch+i i+l l+e e+sil（sil表示语音结束后的静音，A+B表示受到B影响的A）。实际中以同时考虑前后各一个音素的三音子最为常见，最多也有人使用四音子模型。使用三音子或四音子模型会导致 分类目标的几何增长（如仅仅30个音素就可以扩展出30^3=27000个三音子）， 并再次导致数据稀疏的问题。最常用的解决方法是使用基于决策树的方式对这些三音子或四音子模型进行聚类，对每一类模型进行参数共享以及训练数据的共享。在构建决策树的方式上以及决策树进行自顶向下的 分裂过程中，都可以 导入适当的语音学知识， 将知识与数据驱动的方法进行结合， 同时还可以 减少运算量并在识别中 使用训练数据中未出现的三音子模型等。<br><br>有了具体的分类的目标（比如三音子）之后，下面就要选择具体的数学模型进行声学建模。这里可以根据语音学等研究 使用多种线性结构或非线性结构的模型或模型组合。目前最广泛使用的仍然是基于隐式马尔科夫模型的建模方法，即对每个三音子分别建立一个模型，具体可以参见楼上的回答。隐式马尔科夫模型的转移概率密度以几何分布最为常见，但语音合成中也常用高斯分布；观测概率密度函数传统上通常使用 高斯混合模型，也有人使用人工神经网络等，近年来随着深度学习的发展，使用各种深层神经网络的情况 越来越多。最近也有人使用不同方法直接利用递归神经网络进行建模，有一些工作也取得了比较好的效果。但无论使用哪种模型甚至非线性的模型 组合，背后的含义都是假设了对应于每种 类别（三音子）的语音帧在它所对应的高维空间中具有几乎确定的空间分布，可以通过对空间进行划分，并由未知语音帧的空间位置来对语音帧进行正确的分类。<br><br>在完成声学模型建模后，就可以基于声学模型对未知语音帧序列进行语音识别了，这一过程通常称为搜索解码过程。解码的原理通常是在给定了根据语法、字典对马尔科夫模型进行连接后的搜索的网络（网络的每个节点可以是一个词组等）后，在所有可能的搜索路径中选择一条或多条最优（通常是最大后验概率）路径（字典中出现词组的词组串）作为识别结果，具体的搜索算法可以有不同的实现方式。这样的搜索可以对时序的语音帧根据其前后帧进行约束；注意使用多状态 隐式马尔科夫模型的理由之一是可以在 搜索中对每个三音子的最短长度施加限制。语音识别任务通常有不同的分类，最困难的问题是所谓大词表连续语音识别，即对可能由数万种日常用词组成的发音自然的语句（比如我们日常随意对话中的语句）进行识别，这样的 问题中通常要 将声学模型同概率语言模型联合使用，即在搜索中导入 统计获得的先验语言层级信息，优点是可以显著的提高识别器的性能，缺点是也会造成识别器明显偏向于识别出语言模型中 出现过的信息。<br><br>以上就是我理解的语音识别的原理，包括大致的系统构成和基本设计思路。具体在最前沿的研究和评测 中，通常还需要把许多不同的语音识别器通过各种不同的手段进行系统组合，以便在最终使最终的（组合）系统 能够获得具有互补性的信息，从而得到最佳的识别效果。</span></div><div><div class="ContentItem-time"><a target="_blank" href="/question/20398418/answer/71349128"><span data-tooltip="发布于 2015-11-08">编辑于 2016-07-29</span></a></div></div><div class="ContentItem-actions RichContent-actions"><span><button class="Button VoteButton VoteButton--up" aria-label="赞同" type="button"><svg viewBox="0 0 20 18" class="Icon VoteButton-upIcon Icon--triangle" style="height:16px;width:9px;" width="9" height="16" aria-hidden="true"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"/></g></svg>181</button><button class="Button VoteButton VoteButton--down" aria-label="反对" type="button"><svg viewBox="0 0 20 18" class="Icon VoteButton-downIcon Icon--triangle" style="height:16px;width:9px;" width="9" height="16" aria-hidden="true"><title></title><g><path d="M0 15.243c0-.326.088-.533.236-.896l7.98-13.204C8.57.57 9.086 0 10 0s1.43.57 1.784 1.143l7.98 13.204c.15.363.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H1.955c-1.08 0-1.955-.517-1.955-1.9z"/></g></svg></button></span><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--comment Icon--left" style="height:16px;width:12px;" width="12" height="16" aria-hidden="true"><title></title><g><path d="M7.24 16.313c-.272-.047-.553.026-.77.2-1.106.813-2.406 1.324-3.77 1.482-.16.017-.313-.06-.394-.197-.082-.136-.077-.308.012-.44.528-.656.906-1.42 1.11-2.237.04-.222-.046-.45-.226-.588C1.212 13.052.027 10.73 0 8.25 0 3.7 4.03 0 9 0s9 3.7 9 8.25-4.373 9.108-10.76 8.063z"/></g></svg>15 条评论</button><div class="Popover ShareMenu ContentItem-action"><div id="null-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="null-content"><button class="Button Button--plain" type="button"><svg viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--share Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M.93 3.89C-.135 4.13-.343 5.56.614 6.098L5.89 9.005l8.168-4.776c.25-.128.477.197.273.388L7.05 10.66l.926 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.243c.584-.892-.212-2.03-1.234-1.796L.93 3.89z"/></g></svg>分享</button></div></div><button class="Button ContentItem-action Button--plain" type="button"><svg viewBox="0 0 20 20" class="Icon Icon--star Icon--left" style="height:16px;width:13px;" width="13" height="16" aria-hidden="true"><title></title><g><path d="M3.515 17.64l.918-5.355-3.89-3.792c-.926-.902-.64-1.784.64-1.97L6.56 5.74 8.964.87c.572-1.16 1.5-1.16 2.072 0l2.404 4.87 5.377.783c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.22 1.274-.532 1.82-1.676 1.218L10 16.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z"/></g></svg>收藏</button><button class="Button ContentItem-action Button--plain" type="button"><svg width="14" height="16" viewBox="0 0 20 18" xmlns="http://www.w3.org/2000/svg" class="Icon Icon--thank Icon--left" style="height:16px;width:14px;" aria-hidden="true"><title></title><g><path d="M0 5.437C0 2.505 2.294.094 5.207 0 7.243 0 9.092 1.19 10 3c.823-1.758 2.65-3 4.65-3C17.546 0 20 2.507 20 5.432 20 13.24 11.842 18 10 18 8.158 18 0 13.24 0 5.437z" fill-rule="evenodd"/></g></svg>感谢</button><button class="Button ContentItem-action ContentItem-rightButton Button--plain" data-zop-retract-question="true" type="button"><span class="RichContent-collapsedText">收起</span><svg viewBox="0 0 10 6" class="Icon ContentItem-arrowIcon is-active Icon--arrow" style="height:16px;width:10px;" width="10" height="16" aria-hidden="true"><title></title><g><path d="M8.716.217L5.002 4 1.285.218C.99-.072.514-.072.22.218c-.294.29-.294.76 0 1.052l4.25 4.512c.292.29.77.29 1.063 0L9.78 1.27c.293-.29.293-.76 0-1.052-.295-.29-.77-.29-1.063 0z"/></g></svg></button></div></div></div></div></div></div></div><div class="Card"><button class="Button QuestionMainAction" type="button">查看更多回答</button></div></div><div class="CollapsedAnswers-bar"><button class="Button Button--plain" type="button">9 个回答被折叠</button>（<a class="Button Button--plain" target="_blank" type="button" href="/question/20120168">为什么？</a>）</div></div></div></div></div></main></div></div><div id="data" style="display:none;" data-state="{&quot;loading&quot;:{&quot;global&quot;:{&quot;count&quot;:0},&quot;local&quot;:{&quot;token/&quot;:false,&quot;env/getExperiments/&quot;:false,&quot;config/getAppConfig/&quot;:false,&quot;question/get/&quot;:false,&quot;question/getAnswers/20398418&quot;:false}},&quot;entities&quot;:{&quot;users&quot;:{},&quot;questions&quot;:{&quot;20398418&quot;:{&quot;status&quot;:{&quot;isLocked&quot;:false,&quot;isClose&quot;:false,&quot;isEvaluate&quot;:false,&quot;isSuggest&quot;:false},&quot;visitCount&quot;:317537,&quot;relationship&quot;:{&quot;concernedFollowers&quot;:[],&quot;isAnonymous&quot;:false,&quot;canLock&quot;:false,&quot;isFollowing&quot;:false,&quot;isAuthor&quot;:false,&quot;canCollapseAnswers&quot;:false,&quot;canStickAnswers&quot;:false},&quot;isMuted&quot;:false,&quot;topics&quot;:[{&quot;introduction&quot;:&quot;人工智能(Artificial Intelligence, AI )是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学，是指由人工制造出来的系统所表现出来的智能。 人工智能目前在计算机领域内，得到了愈加广泛的发挥。并在机器人、经济政治决策、控制系统、仿真系统中得到应用。&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/13e388fe4_is.jpg&quot;,&quot;name&quot;:&quot;人工智能&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19551275&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;人工智能(Artificial Intelligence, AI )是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学，是指由人工制造出来的系统所表现出来的智能。 人工智能目前在计算机领域内，得到了愈加广泛的发挥。并在机器人、经济政治决策、控制系统、仿真系统中得到应用。&quot;,&quot;id&quot;:&quot;19551275&quot;},{&quot;introduction&quot;:&quot;科学知识的普及。&quot;,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/v2-d8200aeed66c238b2df2f2431b001dcb_is.jpg&quot;,&quot;name&quot;:&quot;科普&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19551585&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;科学知识的普及。&quot;,&quot;id&quot;:&quot;19551585&quot;},{&quot;introduction&quot;:&quot;语音识别技术（Speech recognition）是指将人类语音中的词汇内容转换为计算机可读的输入，例如按键、二进制编码或者字符序列。&quot;,&quot;avatarUrl&quot;:&quot;https://pic3.zhimg.com/9452b2efedcc9b1705362562480e0cce_is.jpg&quot;,&quot;name&quot;:&quot;语音识别&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19560846&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;语音识别技术（Speech recognition）是指将人类语音中的词汇内容转换为计算机可读的输入，例如按键、二进制编码或者字符序列。&quot;,&quot;id&quot;:&quot;19560846&quot;},{&quot;introduction&quot;:&quot;&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/4dd7e075c_is.jpg&quot;,&quot;name&quot;:&quot;X 的原理&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19561178&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;&quot;,&quot;id&quot;:&quot;19561178&quot;},{&quot;introduction&quot;:&quot;&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/fc396ead0_is.jpg&quot;,&quot;name&quot;:&quot;X 的工作原理&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/topics/19566024&quot;,&quot;type&quot;:&quot;topic&quot;,&quot;excerpt&quot;:&quot;&quot;,&quot;id&quot;:&quot;19566024&quot;}],&quot;excerpt&quot;:&quot;本题已收录至知乎圆桌：&lt;a href=\&quot;https://www.zhihu.com/roundtable/ziranyuyan\&quot; class=\&quot;internal\&quot;&gt;人工智能 · 语言智能&lt;/a&gt;，更多「人工智能」相关话题欢迎关注讨论&quot;,&quot;adminClosedComment&quot;:false,&quot;except&quot;:&quot;本题已收录至知乎圆桌：&lt;a href=\&quot;https://www.zhihu.com/roundtable/ziranyuyan\&quot; class=\&quot;internal\&quot;&gt;人工智能 · 语言智能&lt;/a&gt;，更多「人工智能」相关话题欢迎关注讨论&quot;,&quot;isEditable&quot;:false,&quot;answerCount&quot;:23,&quot;editableDetail&quot;:&quot;&lt;p&gt;本题已收录至知乎圆桌：&lt;a href=\&quot;https://www.zhihu.com/roundtable/ziranyuyan\&quot; data-editable=\&quot;true\&quot; data-title=\&quot;人工智能 · 语言智能 - 知乎\&quot; class=\&quot;\&quot;&gt;人工智能 · 语言智能&lt;/a&gt;，更多「人工智能」相关话题欢迎关注讨论&lt;/p&gt;&quot;,&quot;id&quot;:20398418,&quot;collapsedAnswerCount&quot;:9,&quot;author&quot;:{&quot;isFollowed&quot;:false,&quot;avatarUrlTemplate&quot;:&quot;https://pic4.zhimg.com/5e52d80dd864ad980fdeadc1093e821b_{size}.jpg&quot;,&quot;type&quot;:&quot;people&quot;,&quot;name&quot;:&quot;马云&quot;,&quot;isAdvertiser&quot;:false,&quot;headline&quot;:&quot;公众号【嘿嘿Beta】welcomebeta&quot;,&quot;badge&quot;:[],&quot;userType&quot;:&quot;people&quot;,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/b97dfc7321b692f6589797c19d5463d3&quot;,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/5e52d80dd864ad980fdeadc1093e821b_is.jpg&quot;,&quot;isFollowing&quot;:false,&quot;isOrg&quot;:false,&quot;gender&quot;:1,&quot;urlToken&quot;:&quot;mayun&quot;,&quot;id&quot;:&quot;b97dfc7321b692f6589797c19d5463d3&quot;},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/questions/20398418&quot;,&quot;commentPermission&quot;:&quot;all&quot;,&quot;created&quot;:1344006068,&quot;detail&quot;:&quot;&lt;p&gt;本题已收录至知乎圆桌：&lt;a href=\&quot;https://www.zhihu.com/roundtable/ziranyuyan\&quot; class=\&quot;internal\&quot;&gt;人工智能 · 语言智能&lt;/a&gt;，更多「人工智能」相关话题欢迎关注讨论&lt;/p&gt;&quot;,&quot;updatedTime&quot;:1494170252,&quot;isReportable&quot;:true,&quot;hasPublishingDraft&quot;:false,&quot;commentCount&quot;:3,&quot;allowDelete&quot;:false,&quot;questionType&quot;:&quot;normal&quot;,&quot;followerCount&quot;:4567,&quot;title&quot;:&quot;语音识别的技术原理是什么？&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;type&quot;:&quot;question&quot;,&quot;suggestEdit&quot;:{&quot;status&quot;:false,&quot;reason&quot;:&quot;&quot;},&quot;isNormal&quot;:true}},&quot;answers&quot;:{&quot;18080841&quot;:{&quot;stickyInfo&quot;:&quot;&quot;,&quot;relationship&quot;:{&quot;upvotedFollowees&quot;:[],&quot;isAuthor&quot;:false,&quot;isNothelp&quot;:false,&quot;isAuthorized&quot;:false,&quot;voting&quot;:0,&quot;isThanked&quot;:false},&quot;editableContent&quot;:&quot;&quot;,&quot;markInfos&quot;:[{&quot;markType&quot;:&quot;editor_recommendation&quot;},{&quot;markType&quot;:&quot;weekly&quot;}],&quot;excerpt&quot;:&quot;简要给大家介绍一下语音怎么变文字的吧。&lt;b&gt;需要说明的是，这篇文章为了易读性而牺牲了严谨性，因此文中的很多表述实际上是不准确的。&lt;/b&gt;对于有兴趣深入了解的同学，本文的末尾推荐了几份进阶阅读材料。下面我们开始。 首先，我们知道声音实际上是一种波。常见的m…&quot;,&quot;annotationAction&quot;:[],&quot;adminClosedComment&quot;:false,&quot;collapsedBy&quot;:&quot;nobody&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;createdTime&quot;:1374845772,&quot;updatedTime&quot;:1484362437,&quot;id&quot;:18080841,&quot;voteupCount&quot;:2178,&quot;collapseReason&quot;:&quot;&quot;,&quot;isCollapsed&quot;:false,&quot;author&quot;:{&quot;isFollowed&quot;:false,&quot;avatarUrlTemplate&quot;:&quot;https://pic1.zhimg.com/1be9d5c0ccc6b73c724ed50812dc2350_{size}.jpg&quot;,&quot;userType&quot;:&quot;people&quot;,&quot;isFollowing&quot;:false,&quot;type&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;jimbozhang&quot;,&quot;id&quot;:&quot;4d29efdd93412a11cdafee99dba4fd9b&quot;,&quot;name&quot;:&quot;张俊博&quot;,&quot;isAdvertiser&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/4d29efdd93412a11cdafee99dba4fd9b&quot;,&quot;gender&quot;:1,&quot;headline&quot;:&quot;小米语音&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/1be9d5c0ccc6b73c724ed50812dc2350_is.jpg&quot;,&quot;isOrg&quot;:false,&quot;followerCount&quot;:2061,&quot;badge&quot;:[]},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/answers/18080841&quot;,&quot;commentPermission&quot;:&quot;all&quot;,&quot;isSticky&quot;:false,&quot;question&quot;:{&quot;author&quot;:{&quot;isFollowed&quot;:false,&quot;avatarUrlTemplate&quot;:&quot;https://pic4.zhimg.com/5e52d80dd864ad980fdeadc1093e821b_{size}.jpg&quot;,&quot;name&quot;:&quot;马云&quot;,&quot;isAdvertiser&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/b97dfc7321b692f6589797c19d5463d3&quot;,&quot;gender&quot;:1,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;mayun&quot;,&quot;headline&quot;:&quot;公众号【嘿嘿Beta】welcomebeta&quot;,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/5e52d80dd864ad980fdeadc1093e821b_is.jpg&quot;,&quot;isFollowing&quot;:false,&quot;isOrg&quot;:false,&quot;type&quot;:&quot;people&quot;,&quot;badge&quot;:[],&quot;id&quot;:&quot;b97dfc7321b692f6589797c19d5463d3&quot;},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/questions/20398418&quot;,&quot;created&quot;:1344006068,&quot;updatedTime&quot;:1494170252,&quot;questionType&quot;:&quot;normal&quot;,&quot;title&quot;:&quot;语音识别的技术原理是什么？&quot;,&quot;type&quot;:&quot;question&quot;,&quot;id&quot;:20398418},&quot;suggestEdit&quot;:{&quot;status&quot;:false,&quot;reason&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;url&quot;:&quot;&quot;,&quot;unnormalDetails&quot;:{},&quot;tip&quot;:&quot;&quot;},&quot;content&quot;:&quot;简要给大家介绍一下语音怎么变文字的吧。&lt;b&gt;需要说明的是，这篇文章为了易读性而牺牲了严谨性，因此文中的很多表述实际上是不准确的。&lt;/b&gt;对于有兴趣深入了解的同学，本文的末尾推荐了几份进阶阅读材料。下面我们开始。&lt;br&gt;&lt;br&gt;首先，我们知道声音实际上是一种波。常见的mp3等格式都是压缩格式，必须转成非压缩的纯波形文件来处理，比如Windows PCM文件，也就是俗称的wav文件。wav文件里存储的除了一个文件头以外，就是声音波形的一个个点了。下图是一个波形的示例。&lt;br&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_b.jpg\&quot; data-rawheight=\&quot;119\&quot; data-rawwidth=\&quot;482\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;482\&quot; data-original=\&quot;https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_r.jpg\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawheight=\&quot;119\&quot; data-rawwidth=\&quot;482\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;482\&quot; data-original=\&quot;https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_r.jpg\&quot; data-actualsrc=\&quot;https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_b.jpg\&quot;&gt;&lt;br&gt;在开始语音识别之前，有时需要把首尾端的静音切除，降低对后续步骤造成的干扰。这个静音切除的操作一般称为VAD，需要用到信号处理的一些技术。&lt;br&gt;&lt;br&gt;要对声音进行分析，需要对声音分帧，也就是把声音切开成一小段一小段，每小段称为一帧。分帧操作一般不是简单的切开，而是使用移动窗函数来实现，这里不详述。帧与帧之间一般是有交叠的，就像下图这样：&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic3.zhimg.com/554db0c9107727aa1e31a62cca782ada_b.jpg\&quot; data-rawheight=\&quot;175\&quot; data-rawwidth=\&quot;343\&quot; class=\&quot;content_image\&quot; width=\&quot;343\&quot;&gt;图中，每帧的长度为25毫秒，每两帧之间有25-10=15毫秒的交叠。我们称为以帧长25ms、帧移10ms分帧。&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawheight=\&quot;175\&quot; data-rawwidth=\&quot;343\&quot; class=\&quot;content_image lazy\&quot; width=\&quot;343\&quot; data-actualsrc=\&quot;https://pic3.zhimg.com/554db0c9107727aa1e31a62cca782ada_b.jpg\&quot;&gt;图中，每帧的长度为25毫秒，每两帧之间有25-10=15毫秒的交叠。我们称为以帧长25ms、帧移10ms分帧。&lt;br&gt;&lt;br&gt;分帧后，语音就变成了很多小段。但波形在时域上几乎没有描述能力，因此必须将波形作变换。常见的一种变换方法是提取MFCC特征，根据人耳的生理特性，把每一帧波形变成一个多维向量，可以简单地理解为这个向量包含了这帧语音的内容信息。这个过程叫做声学特征提取。实际应用中，这一步有很多细节，声学特征也不止有MFCC这一种，具体这里不讲。&lt;br&gt;&lt;br&gt;至此，声音就成了一个12行（假设声学特征是12维）、N列的一个矩阵，称之为观察序列，这里N为总帧数。观察序列如下图所示，图中，每一帧都用一个12维的向量表示，色块的颜色深浅表示向量值的大小。&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic4.zhimg.com/c5cc0131dc6d38e871953eea0792f7db_b.jpg\&quot; data-rawheight=\&quot;318\&quot; data-rawwidth=\&quot;301\&quot; class=\&quot;content_image\&quot; width=\&quot;301\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawheight=\&quot;318\&quot; data-rawwidth=\&quot;301\&quot; class=\&quot;content_image lazy\&quot; width=\&quot;301\&quot; data-actualsrc=\&quot;https://pic4.zhimg.com/c5cc0131dc6d38e871953eea0792f7db_b.jpg\&quot;&gt;&lt;br&gt;接下来就要介绍怎样把这个矩阵变成文本了。首先要介绍两个概念：&lt;br&gt;&lt;ol&gt;&lt;li&gt;音素：单词的发音由音素构成。对英语，一种常用的音素集是卡内基梅隆大学的一套由39个音素构成的音素集，参见&lt;a href=\&quot;https://link.zhihu.com/?target=http%3A//www.speech.cs.cmu.edu/cgi-bin/cmudict\&quot; class=\&quot; wrap external\&quot; target=\&quot;_blank\&quot; rel=\&quot;nofollow noreferrer\&quot;&gt;The CMU Pronouncing Dictionary&lt;i class=\&quot;icon-external\&quot;&gt;&lt;/i&gt;&lt;/a&gt;‎。汉语一般直接用全部声母和韵母作为音素集，另外汉语识别还分有调无调，不详述。&lt;br&gt;&lt;/li&gt;&lt;li&gt;状态：这里理解成比音素更细致的语音单位就行啦。通常把一个音素划分成3个状态。&lt;/li&gt;&lt;/ol&gt;&lt;br&gt;语音识别是怎么工作的呢？实际上一点都不神秘，无非是：&lt;br&gt;把帧识别成状态（难点）。&lt;br&gt;把状态组合成音素。&lt;br&gt;把音素组合成单词。&lt;br&gt;&lt;br&gt;如下图所示：&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic2.zhimg.com/beee2a3ce7b1b56de362c9015e5b8ccd_b.jpg\&quot; data-rawheight=\&quot;257\&quot; data-rawwidth=\&quot;457\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;457\&quot; data-original=\&quot;https://pic2.zhimg.com/beee2a3ce7b1b56de362c9015e5b8ccd_r.jpg\&quot;&gt;图中，每个小竖条代表一帧，若干帧语音对应一个状态，每三个状态组合成一个音素，若干个音素组合成一个单词。也就是说，只要知道每帧语音对应哪个状态了，语音识别的结果也就出来了。&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawheight=\&quot;257\&quot; data-rawwidth=\&quot;457\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;457\&quot; data-original=\&quot;https://pic2.zhimg.com/beee2a3ce7b1b56de362c9015e5b8ccd_r.jpg\&quot; data-actualsrc=\&quot;https://pic2.zhimg.com/beee2a3ce7b1b56de362c9015e5b8ccd_b.jpg\&quot;&gt;图中，每个小竖条代表一帧，若干帧语音对应一个状态，每三个状态组合成一个音素，若干个音素组合成一个单词。也就是说，只要知道每帧语音对应哪个状态了，语音识别的结果也就出来了。&lt;br&gt;&lt;br&gt;那每帧音素对应哪个状态呢？有个容易想到的办法，看某帧对应哪个状态的概率最大，那这帧就属于哪个状态。比如下面的示意图，这帧在状态S3上的条件概率最大，因此就猜这帧属于状态S3。&lt;noscript&gt;&lt;img src=\&quot;https://pic2.zhimg.com/61d5bff9c239e7519e92d98f5bc44689_b.jpg\&quot; data-rawheight=\&quot;211\&quot; data-rawwidth=\&quot;341\&quot; class=\&quot;content_image\&quot; width=\&quot;341\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawheight=\&quot;211\&quot; data-rawwidth=\&quot;341\&quot; class=\&quot;content_image lazy\&quot; width=\&quot;341\&quot; data-actualsrc=\&quot;https://pic2.zhimg.com/61d5bff9c239e7519e92d98f5bc44689_b.jpg\&quot;&gt;&lt;br&gt;&lt;br&gt;那这些用到的概率从哪里读取呢？有个叫“声学模型”的东西，里面存了一大堆参数，通过这些参数，就可以知道帧和状态对应的概率。获取这一大堆参数的方法叫做“训练”，需要使用巨大数量的语音数据，训练的方法比较繁琐，这里不讲。&lt;br&gt;&lt;br&gt;但这样做有一个问题：每一帧都会得到一个状态号，最后整个语音就会得到一堆乱七八糟的状态号。假设语音有1000帧，每帧对应1个状态，每3个状态组合成一个音素，那么大概会组合成300个音素，但这段语音其实根本没有这么多音素。如果真这么做，得到的状态号可能根本无法组合成音素。实际上，相邻帧的状态应该大多数都是相同的才合理，因为每帧很短。&lt;br&gt;&lt;br&gt;解决这个问题的常用方法就是使用隐马尔可夫模型（Hidden Markov Model，HMM）。这东西听起来好像很高深的样子，实际上用起来很简单：&lt;br&gt;第一步，构建一个状态网络。&lt;br&gt;第二步，从状态网络中寻找与声音最匹配的路径。&lt;br&gt;&lt;br&gt;这样就把结果限制在预先设定的网络中，避免了刚才说到的问题，当然也带来一个局限，比如你设定的网络里只包含了“今天晴天”和“今天下雨”两个句子的状态路径，那么不管说些什么，识别出的结果必然是这两个句子中的一句。&lt;br&gt;&lt;br&gt;那如果想识别任意文本呢？把这个网络搭得足够大，包含任意文本的路径就可以了。但这个网络越大，想要达到比较好的识别准确率就越难。所以要根据实际任务的需求，合理选择网络大小和结构。&lt;br&gt;&lt;br&gt;搭建状态网络，是由单词级网络展开成音素网络，再展开成状态网络。语音识别过程其实就是在状态网络中搜索一条最佳路径，语音对应这条路径的概率最大，这称之为“解码”。路径搜索的算法是一种动态规划剪枝的算法，称之为Viterbi算法，用于寻找全局最优路径。&lt;br&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic1.zhimg.com/91e4cb3b716b63d5e18ba710a1a2d770_b.jpg\&quot; data-rawheight=\&quot;329\&quot; data-rawwidth=\&quot;621\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;621\&quot; data-original=\&quot;https://pic1.zhimg.com/91e4cb3b716b63d5e18ba710a1a2d770_r.jpg\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawheight=\&quot;329\&quot; data-rawwidth=\&quot;621\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;621\&quot; data-original=\&quot;https://pic1.zhimg.com/91e4cb3b716b63d5e18ba710a1a2d770_r.jpg\&quot; data-actualsrc=\&quot;https://pic1.zhimg.com/91e4cb3b716b63d5e18ba710a1a2d770_b.jpg\&quot;&gt;&lt;br&gt;这里所说的累积概率，由三部分构成，分别是：&lt;br&gt;&lt;ol&gt;&lt;li&gt;观察概率：每帧和每个状态对应的概率&lt;/li&gt;&lt;li&gt;转移概率：每个状态转移到自身或转移到下个状态的概率&lt;/li&gt;&lt;li&gt;语言概率：根据语言统计规律得到的概率&lt;/li&gt;&lt;/ol&gt;其中，前两种概率从声学模型中获取，最后一种概率从语言模型中获取。语言模型是使用大量的文本训练出来的，可以利用某门语言本身的统计规律来帮助提升识别正确率。语言模型很重要，如果不使用语言模型，当状态网络较大时，识别出的结果基本是一团乱麻。&lt;br&gt;&lt;br&gt;&lt;br&gt;这样基本上语音识别过程就完成了。&lt;br&gt;&lt;br&gt;以上的文字只是想让大家容易理解，并不追求严谨。事实上，HMM的内涵绝不是上面所说的“无非是个状态网络”，如果希望深入了解，下面给出了几篇阅读材料：&lt;br&gt;&lt;br&gt;1. Rabiner L R. &lt;i&gt;A tutorial on hidden Markov models and selected applications in speech recognition&lt;/i&gt;. Proceedings of the IEEE, 1989, 77(2): 257-286.&lt;br&gt;入门必读。深入浅出地介绍了基于HMM的语音识别的原理，不注重公式的细节推导而是着重阐述公式背后的物理意义。&lt;br&gt;&lt;br&gt;2. Bilmes J A. &lt;i&gt;A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models&lt;/i&gt;. International Computer Science Institute, 1998, 4(510): 126.&lt;br&gt;详细介绍了用E-M算法训练HMM参数的推导过程，首先讲E-M的基本原理，然后讲解如何应用到GMM的训练，最后讲解如何应用到HMM的训练。&lt;br&gt;&lt;br&gt;3. Young S, Evermann G, Gales M, et al. &lt;i&gt;The HTK book (v3.4)&lt;/i&gt;. Cambridge University, 2006.&lt;br&gt;HTK Book，开源工具包HTK的文档。虽然现在HTK已经不是最流行的了，但仍然强烈推荐按照书里的第二章流程做一遍，你可以搭建出一个简单的数字串识别系统。&lt;br&gt;&lt;br&gt;4. Graves A. &lt;i&gt;Supervised Sequence Labelling with Recurrent Neural Networks&lt;/i&gt;. Springer Berlin Heidelberg, 2012: 15-35.&lt;br&gt;基于神经网络的语音识别的入门必读。从神经网络的基本结构、BP算法等介绍到 LSTM、CTC。&lt;br&gt;&lt;br&gt;5. 俞栋, 邓力. &lt;i&gt;解析深度学习——语音识别实践&lt;/i&gt;, 电子工业出版社, 2016.&lt;br&gt;高质量的中文资料非常稀有，推荐买一本。最早把深度学习技术应用于语音识别就是这本书的作者。&quot;,&quot;commentCount&quot;:111,&quot;extras&quot;:&quot;&quot;,&quot;reshipmentSettings&quot;:&quot;disallowed&quot;,&quot;thanksCount&quot;:735,&quot;rewardInfo&quot;:{&quot;rewardMemberCount&quot;:0,&quot;tagline&quot;:&quot;&quot;,&quot;rewardTotalMoney&quot;:0,&quot;canOpenReward&quot;:false,&quot;isRewardable&quot;:false},&quot;isCopyable&quot;:false,&quot;type&quot;:&quot;answer&quot;,&quot;thumbnail&quot;:&quot;https://pic2.zhimg.com/c58a25274bcc8788831e6100e9e366fd_200x112.jpg&quot;,&quot;isNormal&quot;:true},&quot;71349128&quot;:{&quot;stickyInfo&quot;:&quot;&quot;,&quot;relationship&quot;:{&quot;upvotedFollowees&quot;:[],&quot;isAuthor&quot;:false,&quot;isNothelp&quot;:false,&quot;isAuthorized&quot;:false,&quot;voting&quot;:0,&quot;isThanked&quot;:false},&quot;editableContent&quot;:&quot;&quot;,&quot;markInfos&quot;:[{&quot;markType&quot;:&quot;editor_recommendation&quot;},{&quot;url&quot;:&quot;https://www.zhihu.com/roundtable/ziranyuyan&quot;,&quot;markType&quot;:&quot;roundtable&quot;}],&quot;excerpt&quot;:&quot;楼上张俊博的回答比较仔细的讲解了基础的经典语音识别算法。我想对算法背后的含义做一个简单的解释，对涉及到的特征提取（包括分帧）、音素建模、字典、隐式马尔科夫模型等可以参阅楼上的回答。 语音识别的第一个特点是要识别的语音的内容（比声韵母等）是…&quot;,&quot;annotationAction&quot;:[],&quot;adminClosedComment&quot;:false,&quot;collapsedBy&quot;:&quot;nobody&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;createdTime&quot;:1446978693,&quot;updatedTime&quot;:1469776989,&quot;id&quot;:71349128,&quot;voteupCount&quot;:181,&quot;collapseReason&quot;:&quot;&quot;,&quot;isCollapsed&quot;:false,&quot;author&quot;:{&quot;isFollowed&quot;:false,&quot;avatarUrlTemplate&quot;:&quot;https://pic1.zhimg.com/da8e974dc_{size}.jpg&quot;,&quot;userType&quot;:&quot;people&quot;,&quot;isFollowing&quot;:false,&quot;type&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;&quot;,&quot;id&quot;:&quot;ee22a8e26b1dd523733d4cd825ff4043&quot;,&quot;name&quot;:&quot;知乎用户&quot;,&quot;isAdvertiser&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/0&quot;,&quot;gender&quot;:-1,&quot;headline&quot;:&quot;&quot;,&quot;avatarUrl&quot;:&quot;https://pic1.zhimg.com/da8e974dc_is.jpg&quot;,&quot;isOrg&quot;:false,&quot;followerCount&quot;:934,&quot;badge&quot;:[]},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/answers/71349128&quot;,&quot;commentPermission&quot;:&quot;all&quot;,&quot;isSticky&quot;:false,&quot;question&quot;:{&quot;author&quot;:{&quot;isFollowed&quot;:false,&quot;avatarUrlTemplate&quot;:&quot;https://pic4.zhimg.com/5e52d80dd864ad980fdeadc1093e821b_{size}.jpg&quot;,&quot;name&quot;:&quot;马云&quot;,&quot;isAdvertiser&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/b97dfc7321b692f6589797c19d5463d3&quot;,&quot;gender&quot;:1,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;mayun&quot;,&quot;headline&quot;:&quot;公众号【嘿嘿Beta】welcomebeta&quot;,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/5e52d80dd864ad980fdeadc1093e821b_is.jpg&quot;,&quot;isFollowing&quot;:false,&quot;isOrg&quot;:false,&quot;type&quot;:&quot;people&quot;,&quot;badge&quot;:[],&quot;id&quot;:&quot;b97dfc7321b692f6589797c19d5463d3&quot;},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/questions/20398418&quot;,&quot;created&quot;:1344006068,&quot;updatedTime&quot;:1494170252,&quot;questionType&quot;:&quot;normal&quot;,&quot;title&quot;:&quot;语音识别的技术原理是什么？&quot;,&quot;type&quot;:&quot;question&quot;,&quot;id&quot;:20398418},&quot;suggestEdit&quot;:{&quot;status&quot;:false,&quot;reason&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;url&quot;:&quot;&quot;,&quot;unnormalDetails&quot;:{},&quot;tip&quot;:&quot;&quot;},&quot;content&quot;:&quot;楼上张俊博的回答比较仔细的讲解了基础的经典语音识别算法。我想对算法背后的含义做一个简单的解释，对涉及到的特征提取（包括分帧）、音素建模、字典、隐式马尔科夫模型等可以参阅楼上的回答。&lt;br&gt;&lt;br&gt;语音识别的第一个特点是要识别的语音的内容（比声韵母等）是不定长时序，也就是说，在识别以前你不可能知道当前的 声韵母有多长，这样在构建统计模型输入语音特征的时候无法简单判定到底该输入0.0到0.5秒还是0.2到0.8秒进行识别，同时多数常见的模型都不方便处理维度不确定的输入特征（注意在一次处理的时候，时间长度转化成了当前的特征维度）。一种简单的解决思路是对语音进行分帧，每一帧占有比较短固定的时 长（比如25ms），再假设说这样的一帧既足够长（可以蕴含 足以判断它属于哪个声韵母的信息），又很平稳（方便进行短时傅里叶分析），这样将每一帧转换为一个特征向量，（依次）分别识别它们属于哪个声韵母，就可以 解决问题。识别的结果可以是比如第100到第105帧是声母c，而第106帧到115帧是韵母eng等。 这种思路有点类似微积分 中的『以直代曲』。另外在实际的分帧过程中，还有很多常用技巧，比如相邻两帧之间有所重叠，或引入与临近帧之间的差分作为额外特征，乃至直接堆叠许多语音帧等等，这些都可以让前述的两个假设更可靠。近年来，研究种也出现了一些更新颖的处理方式，比如用.wav文件的采样点取代分帧并处理后的语音帧，但这样的方法在处理速度及性能上 暂时还没有优势。&lt;br&gt;&lt;br&gt;当我们有了分帧后的语音特征之后，下一步常用的处理是使用某种分类器将之分类成某种跟语音内容相关的类别，如声韵母，这一步通常称作声学模型建模。对于分类目标的选取，最简单的选择可以是词组，或者是组成词组的汉字所对应的音节。但这样的选择方式通常会对训练模型的语音数据提出过高的要求，带来『数据稀疏』的问题，即数据中 很难包含汉语中的所有词组，同时每个词组也很难具有充足的训练样本以保证统计声学模型的可靠性。由于一个词组通常由多个音素的连续发音 构成，常见的音素都包含在国际音标表中，它们具有恰当的数目（通常几十个），以及清晰的定义（由特定的发声器官运动产生），于是音素成了各种语言中的语音识别中都最为常见的 建模选择（汉语的声韵母也是由一到三个音素构成）， 识别中再结合词组到音素的发音字典使用。使用音素也方便对混合语言（如汉语种夹杂英语词汇）进行识别——当然不同母语的人对相同音素的发音也有区别，这是另外一个话题。另外由于人类发生器官运动的连续性，以及某些语言中特定的拼读习惯（比如英语中定冠词『the』在元音和辅音之前有不同读音），会导致发音，尤其是音素的发音受到前后音素的影响，称为『协同发音』。于是 可以进行所谓『上下文相关』的音素（或者考虑到音素实际的拼读，称为音子）分类。比如wo chi le这个序列，可以写为w o ch i l e，这样是普通的『上下文无关』音子序列，也可以考虑前一个音素对当前音素的影响写成sil-w w-o o-ch ch-i i-l l-e （sil表示语音开始前的静音，A-B表示收到A影响的B）或考虑后一个音素的影响写成w+o o+ch ch+i i+l l+e e+sil（sil表示语音结束后的静音，A+B表示受到B影响的A）。实际中以同时考虑前后各一个音素的三音子最为常见，最多也有人使用四音子模型。使用三音子或四音子模型会导致 分类目标的几何增长（如仅仅30个音素就可以扩展出30^3=27000个三音子）， 并再次导致数据稀疏的问题。最常用的解决方法是使用基于决策树的方式对这些三音子或四音子模型进行聚类，对每一类模型进行参数共享以及训练数据的共享。在构建决策树的方式上以及决策树进行自顶向下的 分裂过程中，都可以 导入适当的语音学知识， 将知识与数据驱动的方法进行结合， 同时还可以 减少运算量并在识别中 使用训练数据中未出现的三音子模型等。&lt;br&gt;&lt;br&gt;有了具体的分类的目标（比如三音子）之后，下面就要选择具体的数学模型进行声学建模。这里可以根据语音学等研究 使用多种线性结构或非线性结构的模型或模型组合。目前最广泛使用的仍然是基于隐式马尔科夫模型的建模方法，即对每个三音子分别建立一个模型，具体可以参见楼上的回答。隐式马尔科夫模型的转移概率密度以几何分布最为常见，但语音合成中也常用高斯分布；观测概率密度函数传统上通常使用 高斯混合模型，也有人使用人工神经网络等，近年来随着深度学习的发展，使用各种深层神经网络的情况 越来越多。最近也有人使用不同方法直接利用递归神经网络进行建模，有一些工作也取得了比较好的效果。但无论使用哪种模型甚至非线性的模型 组合，背后的含义都是假设了对应于每种 类别（三音子）的语音帧在它所对应的高维空间中具有几乎确定的空间分布，可以通过对空间进行划分，并由未知语音帧的空间位置来对语音帧进行正确的分类。&lt;br&gt;&lt;br&gt;在完成声学模型建模后，就可以基于声学模型对未知语音帧序列进行语音识别了，这一过程通常称为搜索解码过程。解码的原理通常是在给定了根据语法、字典对马尔科夫模型进行连接后的搜索的网络（网络的每个节点可以是一个词组等）后，在所有可能的搜索路径中选择一条或多条最优（通常是最大后验概率）路径（字典中出现词组的词组串）作为识别结果，具体的搜索算法可以有不同的实现方式。这样的搜索可以对时序的语音帧根据其前后帧进行约束；注意使用多状态 隐式马尔科夫模型的理由之一是可以在 搜索中对每个三音子的最短长度施加限制。语音识别任务通常有不同的分类，最困难的问题是所谓大词表连续语音识别，即对可能由数万种日常用词组成的发音自然的语句（比如我们日常随意对话中的语句）进行识别，这样的 问题中通常要 将声学模型同概率语言模型联合使用，即在搜索中导入 统计获得的先验语言层级信息，优点是可以显著的提高识别器的性能，缺点是也会造成识别器明显偏向于识别出语言模型中 出现过的信息。&lt;br&gt;&lt;br&gt;以上就是我理解的语音识别的原理，包括大致的系统构成和基本设计思路。具体在最前沿的研究和评测 中，通常还需要把许多不同的语音识别器通过各种不同的手段进行系统组合，以便在最终使最终的（组合）系统 能够获得具有互补性的信息，从而得到最佳的识别效果。&quot;,&quot;commentCount&quot;:15,&quot;extras&quot;:&quot;&quot;,&quot;reshipmentSettings&quot;:&quot;allowed&quot;,&quot;thanksCount&quot;:62,&quot;rewardInfo&quot;:{&quot;rewardMemberCount&quot;:0,&quot;tagline&quot;:&quot;&quot;,&quot;rewardTotalMoney&quot;:0,&quot;canOpenReward&quot;:false,&quot;isRewardable&quot;:false},&quot;isCopyable&quot;:true,&quot;type&quot;:&quot;answer&quot;,&quot;thumbnail&quot;:&quot;&quot;,&quot;isNormal&quot;:true},&quot;167412177&quot;:{&quot;stickyInfo&quot;:&quot;&quot;,&quot;relationship&quot;:{&quot;upvotedFollowees&quot;:[],&quot;isAuthor&quot;:false,&quot;isNothelp&quot;:false,&quot;isAuthorized&quot;:false,&quot;voting&quot;:0,&quot;isThanked&quot;:false},&quot;editableContent&quot;:&quot;&quot;,&quot;markInfos&quot;:[{&quot;url&quot;:&quot;https://www.zhihu.com/roundtable/ziranyuyan&quot;,&quot;markType&quot;:&quot;roundtable&quot;}],&quot;excerpt&quot;:&quot;鉴于传统架构的语音识别方法在其他的回答中已经有了详细的介绍，这里主要介绍end-to-end语音识别架构，主要涉及到RNN神经网络结构以及CTC。Outline：1、 语音识别的基本架构2、 声学模型（Acoustic Model，AM）a） 传统模型b）CTC模型c） end-to-end模型3、…&quot;,&quot;annotationAction&quot;:[],&quot;adminClosedComment&quot;:false,&quot;collapsedBy&quot;:&quot;nobody&quot;,&quot;canComment&quot;:{&quot;status&quot;:true,&quot;reason&quot;:&quot;&quot;},&quot;createdTime&quot;:1494397603,&quot;updatedTime&quot;:1494415154,&quot;id&quot;:167412177,&quot;voteupCount&quot;:207,&quot;collapseReason&quot;:&quot;&quot;,&quot;isCollapsed&quot;:false,&quot;author&quot;:{&quot;isFollowed&quot;:false,&quot;avatarUrlTemplate&quot;:&quot;https://pic3.zhimg.com/v2-ada333ee5501eb108c418312e3d8960e_{size}.jpg&quot;,&quot;userType&quot;:&quot;people&quot;,&quot;isFollowing&quot;:false,&quot;type&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;lambert-fan&quot;,&quot;id&quot;:&quot;a1b13ff231d5689102f7c4ac7bd5b6a1&quot;,&quot;name&quot;:&quot;lambert Fan&quot;,&quot;isAdvertiser&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/a1b13ff231d5689102f7c4ac7bd5b6a1&quot;,&quot;gender&quot;:1,&quot;headline&quot;:&quot;Rokid A-lab，语音识别，机器学习，深度学习&quot;,&quot;avatarUrl&quot;:&quot;https://pic3.zhimg.com/v2-ada333ee5501eb108c418312e3d8960e_is.jpg&quot;,&quot;isOrg&quot;:false,&quot;followerCount&quot;:588,&quot;badge&quot;:[]},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/answers/167412177&quot;,&quot;commentPermission&quot;:&quot;all&quot;,&quot;isSticky&quot;:false,&quot;question&quot;:{&quot;author&quot;:{&quot;isFollowed&quot;:false,&quot;avatarUrlTemplate&quot;:&quot;https://pic4.zhimg.com/5e52d80dd864ad980fdeadc1093e821b_{size}.jpg&quot;,&quot;name&quot;:&quot;马云&quot;,&quot;isAdvertiser&quot;:false,&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/people/b97dfc7321b692f6589797c19d5463d3&quot;,&quot;gender&quot;:1,&quot;userType&quot;:&quot;people&quot;,&quot;urlToken&quot;:&quot;mayun&quot;,&quot;headline&quot;:&quot;公众号【嘿嘿Beta】welcomebeta&quot;,&quot;avatarUrl&quot;:&quot;https://pic4.zhimg.com/5e52d80dd864ad980fdeadc1093e821b_is.jpg&quot;,&quot;isFollowing&quot;:false,&quot;isOrg&quot;:false,&quot;type&quot;:&quot;people&quot;,&quot;badge&quot;:[],&quot;id&quot;:&quot;b97dfc7321b692f6589797c19d5463d3&quot;},&quot;url&quot;:&quot;http://www.zhihu.com/api/v4/questions/20398418&quot;,&quot;created&quot;:1344006068,&quot;updatedTime&quot;:1494170252,&quot;questionType&quot;:&quot;normal&quot;,&quot;title&quot;:&quot;语音识别的技术原理是什么？&quot;,&quot;type&quot;:&quot;question&quot;,&quot;id&quot;:20398418},&quot;suggestEdit&quot;:{&quot;status&quot;:false,&quot;reason&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;url&quot;:&quot;&quot;,&quot;unnormalDetails&quot;:{},&quot;tip&quot;:&quot;&quot;},&quot;content&quot;:&quot;&lt;p&gt;鉴于传统架构的语音识别方法在其他的回答中已经有了详细的介绍，这里主要介绍end-to-end语音识别架构，主要涉及到RNN神经网络结构以及CTC。&lt;/p&gt;&lt;p&gt;Outline：&lt;/p&gt;&lt;p&gt;1、 语音识别的基本架构&lt;/p&gt;&lt;p&gt;2、 声学模型（Acoustic Model，AM）&lt;/p&gt;&lt;ul&gt;&lt;li&gt;a） 传统模型&lt;/li&gt;&lt;li&gt;b）CTC模型&lt;/li&gt;&lt;li&gt;c） end-to-end模型&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;3、 语言模型&lt;/p&gt;&lt;p&gt;4、 解码&lt;/p&gt;&lt;p&gt;----------------------------------------------------&lt;/p&gt;&lt;p&gt;&lt;b&gt;1、 语音识别的基本架构&lt;/b&gt;&lt;/p&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic4.zhimg.com/v2-a966e5e1d23bfa77d6300b6963caa72f_b.png\&quot; data-rawwidth=\&quot;956\&quot; data-rawheight=\&quot;570\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;956\&quot; data-original=\&quot;https://pic4.zhimg.com/v2-a966e5e1d23bfa77d6300b6963caa72f_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;956\&quot; data-rawheight=\&quot;570\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;956\&quot; data-original=\&quot;https://pic4.zhimg.com/v2-a966e5e1d23bfa77d6300b6963caa72f_r.png\&quot; data-actualsrc=\&quot;https://pic4.zhimg.com/v2-a966e5e1d23bfa77d6300b6963caa72f_b.png\&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;上式中W表示文字序列，Y表示语音输入。公式1表示语音识别的目标是在给定语音输入的情况下，找到可能性最大的文字序列。根据Baye’ Rule，可以得到公式2，其中分母表示出现这条语音的概率，它相比于求解的文字序列没有参数关系，可以在求解时忽略，进而得到公式3。公式3中第一部分表示给定一个文字序列出现这条音频的概率，它就是语音识别中的声学模型；第二部分表示出现这个文字序列的概率，它就是语音识别中的语言模型。&lt;/p&gt;&lt;br&gt;&lt;p&gt;无论是传统的方法也好，现在火热的深 度神经网络的方法也罢，目前的语音识别架构都没有脱离上面的公式，也就是说都离不开AM和LM。下面分别对这两部分进行介绍&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;b&gt;2、 声学模型（Acoustic Model，AM）&lt;/b&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;声学模型可以理解为是对发声的建模，它能够把语音输入转换成声学表示的输出，更准确的说是给出语音属于某个声学符号的概率。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;a) 传统模型&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;在英文中这个声学符号可以是音节（syllable）或者更小的颗粒度音素（phoneme）；在中文中这个声学符号可以是声韵母或者是颗粒度同英文一样小的音素。那么公式3中的声学模型就可以表示为下面的公式4的形式：&lt;/p&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic3.zhimg.com/v2-cfff7d9f78112ffe67e44d3492756d4e_b.png\&quot; data-rawwidth=\&quot;634\&quot; data-rawheight=\&quot;319\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;634\&quot; data-original=\&quot;https://pic3.zhimg.com/v2-cfff7d9f78112ffe67e44d3492756d4e_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;634\&quot; data-rawheight=\&quot;319\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;634\&quot; data-original=\&quot;https://pic3.zhimg.com/v2-cfff7d9f78112ffe67e44d3492756d4e_r.png\&quot; data-actualsrc=\&quot;https://pic3.zhimg.com/v2-cfff7d9f78112ffe67e44d3492756d4e_b.png\&quot;&gt;&lt;br&gt;&lt;p&gt;其中Q表示发音单位的序列。从公式中可以看到，声学模型最终转换成了一个语音到发音序列的模型和一个发音序列到输出文字序列的字典。这里的发音序列通常是音素，到此为止声学模型是从语音到音素状态的一个描述。为了对不同上下文的音素加以区分，通常使用上下文相关的“三音子”作为建模单元。可以用下图表示：&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic1.zhimg.com/v2-a9df26a46b5ada81e58df9f897e10700_b.png\&quot; data-rawwidth=\&quot;815\&quot; data-rawheight=\&quot;453\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;815\&quot; data-original=\&quot;https://pic1.zhimg.com/v2-a9df26a46b5ada81e58df9f897e10700_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;815\&quot; data-rawheight=\&quot;453\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;815\&quot; data-original=\&quot;https://pic1.zhimg.com/v2-a9df26a46b5ada81e58df9f897e10700_r.png\&quot; data-actualsrc=\&quot;https://pic1.zhimg.com/v2-a9df26a46b5ada81e58df9f897e10700_b.png\&quot;&gt;&lt;p&gt;其中字典部分表示为如下公式5，其意义是把每个文字拆分成若干发音符号的序列。&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic2.zhimg.com/v2-660c0c934a60dbeb0983323ff1629855_b.png\&quot; data-rawwidth=\&quot;605\&quot; data-rawheight=\&quot;194\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;605\&quot; data-original=\&quot;https://pic2.zhimg.com/v2-660c0c934a60dbeb0983323ff1629855_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;605\&quot; data-rawheight=\&quot;194\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;605\&quot; data-original=\&quot;https://pic2.zhimg.com/v2-660c0c934a60dbeb0983323ff1629855_r.png\&quot; data-actualsrc=\&quot;https://pic2.zhimg.com/v2-660c0c934a60dbeb0983323ff1629855_b.png\&quot;&gt;&lt;p&gt;公式4中的声学部分可以继续分解为如下公式6 ：&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic2.zhimg.com/v2-e5c01fcb5733a6eddd9580905b2da3fd_b.png\&quot; data-rawwidth=\&quot;539\&quot; data-rawheight=\&quot;141\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;539\&quot; data-original=\&quot;https://pic2.zhimg.com/v2-e5c01fcb5733a6eddd9580905b2da3fd_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;539\&quot; data-rawheight=\&quot;141\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;539\&quot; data-original=\&quot;https://pic2.zhimg.com/v2-e5c01fcb5733a6eddd9580905b2da3fd_r.png\&quot; data-actualsrc=\&quot;https://pic2.zhimg.com/v2-e5c01fcb5733a6eddd9580905b2da3fd_b.png\&quot;&gt;&lt;p&gt;公式6表示声学建模的颗粒度可以继续分解为更小的状态（state）。通常一个三音子对应有3个状态（静音通常是5个状态），那么声学建模的总数就是 &lt;img src=\&quot;https://www.zhihu.com/equation?tex=3%2AQ%5E3%2B5\&quot; alt=\&quot;3*Q^3+5\&quot; eeimg=\&quot;1\&quot;&gt; 这么多。为了压缩建模单元数量，状态绑定的技术被大量使用，它使得发音类似的状态用一个模型表表示，从而减少了参数量。状态绑定的技术可以使用专家手工编撰的规则，也可以使用数据驱动的方式。具体绑定形式如下图所示：&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic4.zhimg.com/v2-c15bcd9b55f38a93c3ce6d18e1954323_b.png\&quot; data-rawwidth=\&quot;768\&quot; data-rawheight=\&quot;472\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;768\&quot; data-original=\&quot;https://pic4.zhimg.com/v2-c15bcd9b55f38a93c3ce6d18e1954323_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;768\&quot; data-rawheight=\&quot;472\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;768\&quot; data-original=\&quot;https://pic4.zhimg.com/v2-c15bcd9b55f38a93c3ce6d18e1954323_r.png\&quot; data-actualsrc=\&quot;https://pic4.zhimg.com/v2-c15bcd9b55f38a93c3ce6d18e1954323_b.png\&quot;&gt;&lt;p&gt;基于上面的推到，声学模型是一个描述语音和状态之间转换的模型。&lt;/p&gt;&lt;p&gt;此时，引入HMM假设：状态隐变量，语音是观测值，状态之间的跳转符合马尔科夫假设。那么声学模型可以继续表示为如下公式：&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic2.zhimg.com/v2-55951fdb3d5e06ebbf19a529c5c7a2e5_b.png\&quot; data-rawwidth=\&quot;690\&quot; data-rawheight=\&quot;145\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;690\&quot; data-original=\&quot;https://pic2.zhimg.com/v2-55951fdb3d5e06ebbf19a529c5c7a2e5_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;690\&quot; data-rawheight=\&quot;145\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;690\&quot; data-original=\&quot;https://pic2.zhimg.com/v2-55951fdb3d5e06ebbf19a529c5c7a2e5_r.png\&quot; data-actualsrc=\&quot;https://pic2.zhimg.com/v2-55951fdb3d5e06ebbf19a529c5c7a2e5_b.png\&quot;&gt;&lt;br&gt;&lt;p&gt;其中a表示转移概率，b表示发射概率。用图来表示的话就是下图中的结构 ：&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic3.zhimg.com/v2-e2f47e7a8acbe5f0659dfcb0e1ae1676_b.png\&quot; data-rawwidth=\&quot;1011\&quot; data-rawheight=\&quot;922\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;1011\&quot; data-original=\&quot;https://pic3.zhimg.com/v2-e2f47e7a8acbe5f0659dfcb0e1ae1676_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;1011\&quot; data-rawheight=\&quot;922\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;1011\&quot; data-original=\&quot;https://pic3.zhimg.com/v2-e2f47e7a8acbe5f0659dfcb0e1ae1676_r.png\&quot; data-actualsrc=\&quot;https://pic3.zhimg.com/v2-e2f47e7a8acbe5f0659dfcb0e1ae1676_b.png\&quot;&gt;&lt;p&gt;如图中所示，观测概率通常用GMM或是DNN来描述。这就是CD-GMM-HMM架构[Mark Gales, 2006]和CD-DNN-HMM架构[George E. Dahl, 2012]的语音识别声学模型。CD-DNN-HMM的架构这里引用文章中的图表示如下：&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic1.zhimg.com/v2-67ecce103dd4f049b3e952f48b9eb5d8_b.png\&quot; data-rawwidth=\&quot;840\&quot; data-rawheight=\&quot;715\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;840\&quot; data-original=\&quot;https://pic1.zhimg.com/v2-67ecce103dd4f049b3e952f48b9eb5d8_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;840\&quot; data-rawheight=\&quot;715\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;840\&quot; data-original=\&quot;https://pic1.zhimg.com/v2-67ecce103dd4f049b3e952f48b9eb5d8_r.png\&quot; data-actualsrc=\&quot;https://pic1.zhimg.com/v2-67ecce103dd4f049b3e952f48b9eb5d8_b.png\&quot;&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;b) CTC模型&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;在基于CD-DNN-HMM架构的语音识别声学模型中，训练DNN通常需要帧对齐标签。在GMM中，这个对齐操作是通过EM算法不断迭代完成的，而训练DNN时需要用GMM进行对齐则显得非常别扭。因此一种不需要事先进行帧对齐的方法呼之欲出。&lt;/p&gt;&lt;br&gt;&lt;p&gt;此外对于HMM假设一直受到诟病，等到RNN出现之后，使用RNN来对时序关系进行描述来取代HMM成为当时的热潮。&lt;/p&gt;&lt;br&gt;&lt;p&gt;随着神经网络优化技术的发展和GPU计算能力的不断提升，最终使用RNN和CTC来进行建模实现了end-to-end语音识别的声学模型。&lt;/p&gt;&lt;br&gt;&lt;p&gt;CTC的全称是Connectionist Temporal Classification，中文翻译大概是连接时序分类。它要达到的目标就是直接将语音和相应的文字对应起来，实现时序问题的分类。&lt;/p&gt;&lt;p&gt;用公式来描述的话，CTC的公式推导如下：&lt;/p&gt;&lt;img src=\&quot;https://www.zhihu.com/equation?tex=p%28%5Cpi%7Cx%29%3D%5Cprod_%7Bt%3D1%7D%5ETy_%7B%5Cpi_t%7D%5Et%2C+%5Cforall%5Cpi%5Cin+L%27%5ET\&quot; alt=\&quot;p(\\pi|x)=\\prod_{t=1}^Ty_{\\pi_t}^t, \\forall\\pi\\in L&#x27;^T\&quot; eeimg=\&quot;1\&quot;&gt;&lt;p&gt;其中π表示文字序列，X表示语音输入，y表示RNN的输出。由于很多帧可以输出同样的一个文字，同时很多帧也可以没有任何输出，因此定义了一个多对一的函数，把输出序列中重复的字符合并起来，形成唯一的序列，进而公式表示如下：&lt;/p&gt;&lt;img src=\&quot;https://www.zhihu.com/equation?tex=p%28l%7Cx%29%3D%5Csum_%7B%5Cpi%5Cin%5CRe%5E%7B-1%7D%28l%29+%7Dp%28%5Cpi%7Cx%29\&quot; alt=\&quot;p(l|x)=\\sum_{\\pi\\in\\Re^{-1}(l) }p(\\pi|x)\&quot; eeimg=\&quot;1\&quot;&gt;&lt;p&gt;起始l表示对应的标注文本，而π是带有冗余的神经网络输出。求解上述公式，需要使用前后向算法，定义前向因子  &lt;/p&gt;&lt;img src=\&quot;https://www.zhihu.com/equation?tex=%5Calpha_t%28s%29%5Cstackrel%7Bdef%7D%7B%3D%7D+%5Csum_%7B%5Cpi%5Cin+N%5Et%3A%5CRe%28%5Cpi_%7B1%3At%7D%3Dl_%7B1%3As%7D%29%7D%5Cprod_%7Bt%27%3D1%7D%5Ety_%7B%5Cpi_t%27%7D%5E%7Bt%27%7D\&quot; alt=\&quot;\\alpha_t(s)\\stackrel{def}{=} \\sum_{\\pi\\in N^t:\\Re(\\pi_{1:t}=l_{1:s})}\\prod_{t&#x27;=1}^ty_{\\pi_t&#x27;}^{t&#x27;}\&quot; eeimg=\&quot;1\&quot;&gt;&lt;p&gt;和后向因子：&lt;/p&gt;&lt;img src=\&quot;https://www.zhihu.com/equation?tex=%5Cbeta_t%28s%29%5Cstackrel%7Bdef%7D%7B%3D%7D%5Csum_%7B%5Cpi%5Cin+N%5Et%3A%5CRe%28%5Cpi_%7Bt%3AT%7D%29%3Dl_%7Bs%3A%7Cl%7C%7D%7D%5Cprod_%7Bt%27%3Dt%7D%5ETy_%7B%5Cpi_%7Bt%27%7D%7D%5Et\&quot; alt=\&quot;\\beta_t(s)\\stackrel{def}{=}\\sum_{\\pi\\in N^t:\\Re(\\pi_{t:T})=l_{s:|l|}}\\prod_{t&#x27;=t}^Ty_{\\pi_{t&#x27;}}^t\&quot; eeimg=\&quot;1\&quot;&gt;&lt;p&gt;那么神经网络的输出和前后向因子的关系可以表示为：&lt;/p&gt;&lt;img src=\&quot;https://www.zhihu.com/equation?tex=%5Calpha_t%28s%29%5Cbeta_t%28s%29%3D%5Csum_%7B%5Cpi%5Cin%5CRe%5E%7B-1%7D%28l%29%3A%5Cpi_t%3Dl%27_s%7Dy%5Et_%7Bl%27_s%7D%5Cprod_%7Bt%3D1%7D%5ETy_%7B%5Cpi_t%7D%5Et\&quot; alt=\&quot;\\alpha_t(s)\\beta_t(s)=\\sum_{\\pi\\in\\Re^{-1}(l):\\pi_t=l&#x27;_s}y^t_{l&#x27;_s}\\prod_{t=1}^Ty_{\\pi_t}^t\&quot; eeimg=\&quot;1\&quot;&gt;&lt;p&gt;进而得到：&lt;/p&gt;&lt;img src=\&quot;https://www.zhihu.com/equation?tex=p%28l%7Cx%29%3D%5Csum_%7Bs%3D1%7D%5E%7B%7Cl%27%7C%7D+%5Cfrac%7B%5Calpha_t%28s%29%5Cbeta_t%28s%29%7D%7By_%7Bl%27_s%7D%5Et%7D\&quot; alt=\&quot;p(l|x)=\\sum_{s=1}^{|l&#x27;|} \\frac{\\alpha_t(s)\\beta_t(s)}{y_{l&#x27;_s}^t}\&quot; eeimg=\&quot;1\&quot;&gt;&lt;p&gt;利用上述公式，就可以进行神经网络的训练了，这里仍然可以描述为EM的思想：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;E-step：使用BPTT算法优化神经网络参数；&lt;/li&gt;&lt;li&gt;M-step：使用神经网络的输出，重新寻找最有的对齐关系。&lt;/li&gt;&lt;/ul&gt;&lt;br&gt;&lt;p&gt;CTC可以看成是一个分类方法，甚至可以看作是目标函数。在构建end-to-end声学模型的过程中，CTC起到了很好的自动对齐的效果。同传统的基于CD-DNN-HMM的方法相比，对齐效果引用文章[Alex Graves，2006]中的图是这样的效果：&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic2.zhimg.com/v2-782e7d576b9af93c82c416553a50f835_b.png\&quot; data-rawwidth=\&quot;1158\&quot; data-rawheight=\&quot;408\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;1158\&quot; data-original=\&quot;https://pic2.zhimg.com/v2-782e7d576b9af93c82c416553a50f835_r.png\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;1158\&quot; data-rawheight=\&quot;408\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;1158\&quot; data-original=\&quot;https://pic2.zhimg.com/v2-782e7d576b9af93c82c416553a50f835_r.png\&quot; data-actualsrc=\&quot;https://pic2.zhimg.com/v2-782e7d576b9af93c82c416553a50f835_b.png\&quot;&gt;&lt;br&gt;&lt;p&gt;这幅图可以理解：基于帧对齐的方法强制要求切分好的帧对齐到对应的标签上去，而CTC则可以时帧的输出为空，只有少数帧对齐到对应的输出标签上。这样带来的差别就是帧对齐的方法即使输出是正确的，但是在边界区域的切分也很难准确，从而给DNN的训练引入错误。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;c) End-to-end模型&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;由于神经网络强大的建模能力，End-to-end的输出标签也不再需要像传统架构一样的进行细分。例如对于中文，输出不再需要进行细分为状态、音素或者声韵母，直接将汉字作为输出即可；对于英文，考虑到英文单词的数量庞大，可以使用字母作为输出标签。&lt;/p&gt;&lt;br&gt;&lt;p&gt;从这一点出发，我们可以认为神经网络将声学符号到字符串的映射关系也一并建模学习了出来，这部分是在传统的框架中时词典所应承担的任务。针对这个模块，传统框架中有一个专门的建模单元叫做G2P（grapheme-to-phoneme），来处理集外词（out of vocabulary，OOV）。在end-to-end的声学模型中，可以没有词典，没有OOV，也没有G2P。这些全都被建模在一个神经网络中。&lt;/p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p&gt;另外，在传统的框架结构中，语音需要分帧，加窗，提取特征，包括MFCC、PLP等等。在基于神经网络的声学模型中，通常使用更裸的Fbank特征。在End-to-en的识别中，使用更简单的特征比如FFT点，也是常见的做法。或许在不久的将来，语音的采样点也可以作为输入，这就是更加彻底的End-to-end声学模型。&lt;/p&gt;&lt;br&gt;&lt;p&gt;除此之外，End-to-end的声学模型中已经带有了语言模型的信息，它是通过RNN在输出序列上学习得到的。但这个语言模型仍然比较弱，如果外加一个更大数据量的语言模型，解码的效果会更好。因此，End-to-end现在指声学模型部分，等到不需要语言模型的时候，才是完全的end-to-end。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;b&gt;3、 语言模型（Language Model， LM）&lt;/b&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;语言模型的作用可以简单理解为消解多音字的问题，在声学模型给出发音序列之后，从候选的文字序列中找出概率最大的字符串序列。&lt;/p&gt;&lt;br&gt;&lt;p&gt;关于语言模型，目前最常见的是N-Gram语言模型和基于RNN的语言模型，基于CNN的语言模型facebook也有paper发出来。想深入了解的，可以参考我的这篇回答：&lt;/p&gt;&lt;a href=\&quot;https://www.zhihu.com/question/59050053/answer/166979858\&quot; class=\&quot;internal\&quot;&gt;语音识别如何处理汉字中的「同音字」现象？ - 知乎&lt;/a&gt;&lt;br&gt;&lt;p&gt;&lt;b&gt;4、 解码&lt;/b&gt;&lt;/p&gt;&lt;br&gt;&lt;p&gt;传统的语音识别解码都是建立在WFST的基础之上，它是将HMM、词典以及语言模型编译成一个网络。解码就是在这个WFST构造的动态网络空间中，找到最优的输出字符序列。搜索通常使用Viterbi算法，另外为了防止搜索空间爆炸，通常会采用剪枝算法，因此搜索得到的结果可能不是最优结果。&lt;/p&gt;&lt;br&gt;&lt;p&gt;在end-to-end的语音识别系统中，最简单的解码方法是beam search。尽管end-to-end的声学模型中已经包含了一个弱语言模型，但是利用额外的语言模型仍然能够提高识别性能，因此将传统的基于WFST的解码方式和Viterbi算法引入到end-to-end的语音识别系统中也是非常自然的。然而由于声学模型中弱语言模型的存在，解码可能不是最优的。文章[yuki Kanda, 2016]提出在解码的时候，需要将这个若语言模型减掉才能得到最优结果。公式推导如下：&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic3.zhimg.com/v2-f98efb6804ec36593b12a8e5fc47806a_b.png\&quot; data-rawwidth=\&quot;419\&quot; data-rawheight=\&quot;162\&quot; class=\&quot;content_image\&quot; width=\&quot;419\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;419\&quot; data-rawheight=\&quot;162\&quot; class=\&quot;content_image lazy\&quot; width=\&quot;419\&quot; data-actualsrc=\&quot;https://pic3.zhimg.com/v2-f98efb6804ec36593b12a8e5fc47806a_b.png\&quot;&gt;&lt;p&gt;其中Pr(s|X)是CTC的声学模型，α是权重系数。语言模型部分推导如下：&lt;/p&gt;&lt;img src=\&quot;https://www.zhihu.com/equation?tex=Pr%28W%7Cs%29%3D%5Cfrac%7BPr%28s%7CW%29Pr%28W%29%7D%7BPr%28s%29%5E%7B%5Cbeta%7D%7D\&quot; alt=\&quot;Pr(W|s)=\\frac{Pr(s|W)Pr(W)}{Pr(s)^{\\beta}}\&quot; eeimg=\&quot;1\&quot;&gt;&lt;br&gt;&lt;p&gt;其中Pr(s|W)是字符到单词的映射，通常是一对一的。因此上述公式可以表示为如下形式：&lt;/p&gt;&lt;img src=\&quot;https://www.zhihu.com/equation?tex=Pr%28W%7Cs%29%3D%5Cfrac%7BPr%28W%29%7D%7BPr%28s%29%5E%5Cbeta%7D\&quot; alt=\&quot;Pr(W|s)=\\frac{Pr(W)}{Pr(s)^\\beta}\&quot; eeimg=\&quot;1\&quot;&gt;&lt;br&gt;&lt;p&gt;其中Pr(W)是传统的语言模型，Pr(s)是字符语言模型，β权重系数。上面的公式表示在CTC的模型解码时，语言模型需要进行减先验的操作，这个先验就是声学训练数据中的字符语言模型。&lt;/p&gt;&lt;br&gt;&lt;p&gt;&lt;b&gt;参考文献：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1、Mark Gales and Steve Young, The Application of Hidden Markov Models in Speech Recognition, 2006&lt;/p&gt;&lt;p&gt;2、George E. Dahl, Dong Yu, Li Deng, and Alex Acero，Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition，2012&lt;/p&gt;&lt;p&gt;3、Alex Graves，Santiago Fern ́andez，Faustino Gomez，Ju ̈rgen Schmidhuber， Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks，2006&lt;/p&gt;&lt;p&gt;4、Alex Graves , Navdeep Jaitly, Towards End-to-End Speech Recognition with Recurrent Neural Networks, 2014&lt;/p&gt;&lt;p&gt;5、Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, Yonghui Wu,  Exploring the Limits of Language Modeling, 2016&lt;/p&gt;&lt;p&gt;6、Naoyuki Kanda, Xugang Lu, Hisashi Kawai, Maximum A Posteriori based Decoding for CTC Acoustic Models, 2016&lt;/p&gt;&lt;br&gt;&lt;noscript&gt;&lt;img src=\&quot;https://pic1.zhimg.com/v2-0c06cea59054fe02f3b7d9c843dcd48c_b.jpg\&quot; data-rawwidth=\&quot;1096\&quot; data-rawheight=\&quot;412\&quot; class=\&quot;origin_image zh-lightbox-thumb\&quot; width=\&quot;1096\&quot; data-original=\&quot;https://pic1.zhimg.com/v2-0c06cea59054fe02f3b7d9c843dcd48c_r.jpg\&quot;&gt;&lt;/noscript&gt;&lt;img src=\&quot;//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\&quot; data-rawwidth=\&quot;1096\&quot; data-rawheight=\&quot;412\&quot; class=\&quot;origin_image zh-lightbox-thumb lazy\&quot; width=\&quot;1096\&quot; data-original=\&quot;https://pic1.zhimg.com/v2-0c06cea59054fe02f3b7d9c843dcd48c_r.jpg\&quot; data-actualsrc=\&quot;https://pic1.zhimg.com/v2-0c06cea59054fe02f3b7d9c843dcd48c_b.jpg\&quot;&gt;&quot;,&quot;commentCount&quot;:24,&quot;extras&quot;:&quot;&quot;,&quot;reshipmentSettings&quot;:&quot;allowed&quot;,&quot;thanksCount&quot;:51,&quot;rewardInfo&quot;:{&quot;rewardMemberCount&quot;:0,&quot;tagline&quot;:&quot;&quot;,&quot;rewardTotalMoney&quot;:0,&quot;canOpenReward&quot;:false,&quot;isRewardable&quot;:false},&quot;isCopyable&quot;:true,&quot;type&quot;:&quot;answer&quot;,&quot;thumbnail&quot;:&quot;https://pic4.zhimg.com/v2-a966e5e1d23bfa77d6300b6963caa72f_200x112.png&quot;,&quot;isNormal&quot;:true}},&quot;articles&quot;:{},&quot;columns&quot;:{},&quot;topics&quot;:{},&quot;roundtables&quot;:{},&quot;favlists&quot;:{},&quot;comments&quot;:{},&quot;notifications&quot;:{},&quot;ebooks&quot;:{},&quot;activities&quot;:{},&quot;feeds&quot;:{},&quot;pins&quot;:{},&quot;promotions&quot;:{}},&quot;currentUser&quot;:&quot;&quot;,&quot;token&quot;:{&quot;xsrf&quot;:&quot;962addab-1b8e-493e-abfe-6a211a4a9374&quot;,&quot;xUDID&quot;:&quot;AABCcG_bRQyPTmXiKcUKX8W858QWuedhNzc=&quot;},&quot;account&quot;:{&quot;locakTicketStatus&quot;:false,&quot;challenge&quot;:[],&quot;errorStatus&quot;:false,&quot;message&quot;:&quot;&quot;,&quot;isFetching&quot;:false},&quot;notification&quot;:{},&quot;people&quot;:{&quot;isFetching&quot;:false,&quot;activitiesByUser&quot;:{},&quot;answersByUser&quot;:{},&quot;answersSortByVotesByUser&quot;:{},&quot;answersMarkedByUser&quot;:{},&quot;votedAnswersByUser&quot;:{},&quot;thankedAnswersByUser&quot;:{},&quot;voteAnswersByUser&quot;:{},&quot;thankAnswersByUser&quot;:{},&quot;topicAnswersByUser&quot;:{},&quot;articlesByUser&quot;:{},&quot;articlesSortByVotesByUser&quot;:{},&quot;pinsByUser&quot;:{},&quot;questionsByUser&quot;:{},&quot;commercialQuestionsByUser&quot;:{},&quot;favlistsByUser&quot;:{},&quot;followingByUser&quot;:{},&quot;followersByUser&quot;:{},&quot;mutualsByUser&quot;:{},&quot;followingColumnsByUser&quot;:{},&quot;followingQuestionsByUser&quot;:{},&quot;followingFavlistsByUser&quot;:{},&quot;followingTopicsByUser&quot;:{},&quot;publicationsByUser&quot;:{},&quot;columnsByUser&quot;:{},&quot;allFavlistsByUser&quot;:{},&quot;brands&quot;:null},&quot;env&quot;:{&quot;experiment&quot;:{&quot;ge3&quot;:&quot;ge3_9&quot;,&quot;ge2&quot;:&quot;ge2_1&quot;,&quot;nwebStickySidebar&quot;:&quot;sticky&quot;,&quot;favAct&quot;:&quot;default&quot;,&quot;default&quot;:&quot;None&quot;,&quot;mobileQaPageProxyHeifetz&quot;:&quot;m_qa_page_nweb&quot;,&quot;newMore&quot;:&quot;new&quot;,&quot;iOSNewestVersion&quot;:&quot;4.0.0&quot;,&quot;qrcodeLogin&quot;:&quot;qrcode&quot;,&quot;homeUi2&quot;:&quot;default&quot;,&quot;wechatShareModal&quot;:&quot;wechat_share_modal_show&quot;,&quot;qaStickySidebar&quot;:&quot;sticky_sidebar&quot;,&quot;androidProfilePanel&quot;:&quot;panel_a&quot;,&quot;liveStore&quot;:&quot;ls_a3_b1_c2_f1&quot;,&quot;zcmLighting&quot;:&quot;zcm&quot;},&quot;userAgent&quot;:{&quot;Edge&quot;:false,&quot;Wechat&quot;:false,&quot;Weibo&quot;:false,&quot;QQ&quot;:false,&quot;Mobile&quot;:false,&quot;Android&quot;:false,&quot;iOS&quot;:false,&quot;isAppleDevice&quot;:false,&quot;Zhihu&quot;:false,&quot;isBot&quot;:false,&quot;isWebView&quot;:false},&quot;trafficSource&quot;:&quot;&quot;,&quot;edition&quot;:{&quot;baidu&quot;:false,&quot;yidianzixun&quot;:false}},&quot;config&quot;:{&quot;isWindow&quot;:1,&quot;canWrite&quot;:false,&quot;alertTimeSpan&quot;:3600,&quot;tip&quot;:&quot;应国家法规对于帐号实名的要求，进行下一步操作前，需要先完成手机绑定。&quot;},&quot;pushNotifications&quot;:{&quot;default&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;ids&quot;:[]},&quot;follow&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;ids&quot;:[]},&quot;vote-thank&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;ids&quot;:[]},&quot;currentTab&quot;:&quot;default&quot;,&quot;notificationsCount&quot;:{&quot;default&quot;:0,&quot;follow&quot;:0,&quot;vote-thank&quot;:0}},&quot;messages&quot;:{&quot;data&quot;:{},&quot;currentTab&quot;:&quot;common&quot;,&quot;messageCount&quot;:0},&quot;register&quot;:{&quot;registerValidateSucceeded&quot;:null,&quot;registerValidateErrors&quot;:{},&quot;registerConfirmError&quot;:null,&quot;sendDigitsError&quot;:null,&quot;registerConfirmSucceeded&quot;:null},&quot;login&quot;:{&quot;loginConfirmError&quot;:null,&quot;sendDigitsError&quot;:null,&quot;loginConfirmSucceeded&quot;:null,&quot;qrcodeLoginToken&quot;:&quot;&quot;,&quot;qrcodeLoginScanStatus&quot;:0,&quot;qrcodeLoginError&quot;:null,&quot;qrcodeLoginReturnNewToken&quot;:false},&quot;active&quot;:{&quot;sendDigitsError&quot;:null,&quot;activeConfirmSucceeded&quot;:null,&quot;activeConfirmError&quot;:null},&quot;question&quot;:{&quot;followers&quot;:{},&quot;concernedFollowers&quot;:{},&quot;answers&quot;:{&quot;20398418&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;ids&quot;:[18080841,71349128,167412177],&quot;newIds&quot;:[18080841,71349128,167412177],&quot;totals&quot;:23,&quot;isPrevDrained&quot;:true,&quot;previous&quot;:&quot;http://www.zhihu.com/api/v4/questions/20398418/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cadmin_closed_comment%2Creward_info%2Cis_collapsed%2Cannotation_action%2Cannotation_detail%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Ccreated_time%2Cupdated_time%2Creview_info%2Cquestion%2Cexcerpt%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.mark_infos%5B%2A%5D.url%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=3&amp;offset=0&quot;,&quot;next&quot;:&quot;http://www.zhihu.com/api/v4/questions/20398418/answers?sort_by=default&amp;include=data%5B%2A%5D.is_normal%2Cadmin_closed_comment%2Creward_info%2Cis_collapsed%2Cannotation_action%2Cannotation_detail%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Ccreated_time%2Cupdated_time%2Creview_info%2Cquestion%2Cexcerpt%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cupvoted_followees%3Bdata%5B%2A%5D.mark_infos%5B%2A%5D.url%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%3F%28type%3Dbest_answerer%29%5D.topics&amp;limit=3&amp;offset=3&quot;}},&quot;hiddenAnswers&quot;:{},&quot;createdAnswers&quot;:{},&quot;collapsedAnswers&quot;:{},&quot;notificationAnswers&quot;:{},&quot;invitationCandidates&quot;:{},&quot;inviters&quot;:{},&quot;invitees&quot;:{},&quot;similarQuestions&quot;:{},&quot;relatedLives&quot;:{},&quot;recommendReadings&quot;:{},&quot;bio&quot;:{},&quot;brand&quot;:{},&quot;commonAnswerCount&quot;:0,&quot;hiddenAnswerCount&quot;:0},&quot;comments&quot;:{&quot;pagination&quot;:{},&quot;collapsed&quot;:{},&quot;reverse&quot;:{},&quot;reviewing&quot;:{},&quot;conversation&quot;:{},&quot;parent&quot;:{}},&quot;shareTexts&quot;:{},&quot;answers&quot;:{&quot;voters&quot;:{},&quot;copyrightApplicants&quot;:{},&quot;favlists&quot;:{},&quot;newAnswer&quot;:{}},&quot;banner&quot;:{},&quot;topics&quot;:{&quot;bios&quot;:{}},&quot;captcha&quot;:{&quot;captchaNeeded&quot;:false,&quot;captchaBase64String&quot;:null,&quot;captchaValidationMessage&quot;:null,&quot;loginCaptchaExpires&quot;:false},&quot;sms&quot;:{&quot;supportedCountries&quot;:[]},&quot;explore&quot;:{&quot;recommendations&quot;:{},&quot;hotfeeds&quot;:{}},&quot;articles&quot;:{&quot;voters&quot;:{}},&quot;favlists&quot;:{&quot;relations&quot;:{}},&quot;pins&quot;:{&quot;voters&quot;:{}},&quot;topstory&quot;:{&quot;topstorys&quot;:{&quot;isFetching&quot;:false,&quot;isDrained&quot;:false,&quot;afterId&quot;:0,&quot;items&quot;:[],&quot;next&quot;:null},&quot;sidebar&quot;:null},&quot;upload&quot;:{},&quot;video&quot;:{&quot;data&quot;:{}},&quot;guide&quot;:{&quot;guide&quot;:{&quot;isFetching&quot;:false,&quot;isShowGuide&quot;:false}},&quot;switches&quot;:{},&quot;coupon&quot;:{&quot;isRedeemingCoupon&quot;:false},&quot;reward&quot;:{}}" data-config="{&quot;apiAddress&quot;:&quot;/api/v4/&quot;,&quot;deployEnv&quot;:&quot;production&quot;}" data-reactid="20"></div><script src="https://static.zhihu.com/heifetz/vendor.1f389462803af519e7ae.js" data-reactid="21"></script><script src="https://static.zhihu.com/heifetz/main.raven.2e78533e01729a1a7674.js" async="" data-reactid="22"></script><script src="https://static.zhihu.com/heifetz/main.app.d954a1f8fe75f2d9937b.js" data-reactid="23"></script></body></html>